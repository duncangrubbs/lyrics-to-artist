{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lyrics to Artist\n",
    "\n",
    "We train a neural network on lyrics from 10 different artists. Each artist has 100 songs to train on, and then we test the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries, API, and constants setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius as genius\n",
    "import os\n",
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Duncan's API key, change to your own if you are downloading data\n",
    "geniusCreds = 'Lw6NjXtbU7NndUFHRCcOX9FdLhPzVokLIt9c4LWzsTxM10wF7EICGtWSSso8Ohsq'\n",
    "NUM_OF_SONGS = 100\n",
    "\n",
    "artist_names = [\n",
    "    'James Taylor',\n",
    "    'The Beatles',\n",
    "    'Johnny Cash',\n",
    "    'Van Morrison',\n",
    "    'Bob Dylan',\n",
    "    'Fleetwood Mac',\n",
    "    'Lil Wayne',\n",
    "    'J. Cole',\n",
    "    'Taylor Swift',\n",
    "    'Beyoncé'\n",
    "]\n",
    "\n",
    "api = genius.Genius(geniusCreds)\n",
    "genius.skip_non_songs = True\n",
    "genius.excluded_terms = [\"(Remix)\", \"(Live)\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Raw Lyric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for songs by Taylor Swift...\n",
      "\n",
      "Song 1: \"Lover\"\n",
      "Song 2: \"Look What You Made Me Do\"\n",
      "Song 3: \"End Game\"\n",
      "Song 4: \"ME!\"\n",
      "Song 5: \"You Need To Calm Down\"\n",
      "Song 6: \"...Ready for It?\"\n",
      "Song 7: \"Blank Space\"\n",
      "Song 8: \"Bad Blood (Remix)\"\n",
      "Song 9: \"Call It What You Want\"\n",
      "Song 10: \"Delicate\"\n",
      "Song 11: \"Style\"\n",
      "Song 12: \"Cruel Summer\"\n",
      "Song 13: \"Gorgeous\"\n",
      "Song 14: \"Don’t Blame Me\"\n",
      "Song 15: \"I Did Something Bad\"\n",
      "Song 16: \"The Man\"\n",
      "Song 17: \"Dress\"\n",
      "Song 18: \"The Archer\"\n",
      "Song 19: \"Bad Blood\"\n",
      "Song 20: \"London Boy\"\n",
      "Song 21: \"Miss Americana & The Heartbreak Prince\"\n",
      "Song 22: \"Getaway Car\"\n",
      "Song 23: \"Cornelia Street\"\n",
      "Song 24: \"King of My Heart\"\n",
      "Song 25: \"I Forgot That You Existed\"\n",
      "Song 26: \"Daylight\"\n",
      "Song 27: \"New Year’s Day\"\n",
      "Song 28: \"Death by a Thousand Cuts\"\n",
      "Song 29: \"So It Goes...\"\n",
      "Song 30: \"Wildest Dreams\"\n",
      "Song 31: \"Paper Rings\"\n",
      "Song 32: \"This Is Why We Can’t Have Nice Things\"\n",
      "Song 33: \"False God\"\n",
      "Song 34: \"I Think He Knows\"\n",
      "Song 35: \"Love Story\"\n",
      "Song 36: \"Soon You’ll Get Better\"\n",
      "Song 37: \"Afterglow\"\n",
      "Song 38: \"Dancing with Our Hands Tied\"\n",
      "Song 39: \"All Too Well\"\n",
      "Song 40: \"Shake It Off\"\n",
      "Song 41: \"Clean\"\n",
      "Song 42: \"It’s Nice to Have a Friend\"\n",
      "Song 43: \"Out of the Woods\"\n",
      "Song 44: \"Why She Disappeared [Poem]\"\n",
      "Song 45: \"You Belong with Me\"\n",
      "Song 46: \"I Knew You Were Trouble\"\n",
      "Song 47: \"New Romantics\"\n",
      "Song 48: \"Lover (Remix)\"\n",
      "Song 49: \"22\"\n",
      "Song 50: \"We Are Never Ever Getting Back Together\"\n",
      "Song 51: \"Wonderland\"\n",
      "Song 52: \"You Are in Love\"\n",
      "Song 53: \"Everything Has Changed\"\n",
      "Song 54: \"Safe & Sound\"\n",
      "Song 55: \"This Love\"\n",
      "Song 56: \"All You Had to Do Was Stay\"\n",
      "Song 57: \"I Know Places\"\n",
      "Song 58: \"Reputation [Prologue]\"\n",
      "Song 59: \"State of Grace\"\n",
      "Song 60: \"If You’re Anything Like Me [Poem]\"\n",
      "Song 61: \"Red\"\n",
      "Song 62: \"Dear John\"\n",
      "Song 63: \"Only The Young\"\n",
      "Song 64: \"Welcome to New York\"\n",
      "Song 65: \"I Wish You Would\"\n",
      "Song 66: \"Enchanted\"\n",
      "Song 67: \"How You Get the Girl\"\n",
      "Song 68: \"Last Kiss\"\n",
      "Song 69: \"Begin Again\"\n",
      "Song 70: \"Beautiful Ghosts\"\n",
      "Song 71: \"Mine\"\n",
      "Song 72: \"Back to December\"\n",
      "Song 73: \"Christmas Tree Farm\"\n",
      "Song 74: \"Holy Ground\"\n",
      "Song 75: \"Treacherous\"\n",
      "Song 76: \"Mean\"\n",
      "Song 77: \"Long Live\"\n",
      "Song 78: \"Teardrops On My Guitar\"\n",
      "Song 79: \"The Moment I Knew\"\n",
      "Song 80: \"The Last Time\"\n",
      "Song 81: \"Fifteen\"\n",
      "Song 82: \"The Lucky One\"\n",
      "Song 83: \"Sad Beautiful Tragic\"\n",
      "Song 84: \"Innocent\"\n",
      "Song 85: \"Better Than Revenge\"\n",
      "Song 86: \"Sparks Fly\"\n",
      "Song 87: \"White Horse\"\n",
      "Song 88: \"Our Song\"\n",
      "Song 89: \"I Almost Do\"\n",
      "Song 90: \"Fearless\"\n",
      "Song 91: \"The Story of Us\"\n",
      "Song 92: \"Breathe\"\n",
      "Song 93: \"Starlight\"\n",
      "Song 94: \"Haunted\"\n",
      "Song 95: \"Come Back... Be Here\"\n",
      "Song 96: \"Picture to Burn\"\n",
      "Song 97: \"Forever & Always\"\n",
      "Song 98: \"Ours\"\n",
      "Song 99: \"I Knew You Were Trouble (Intro)\"\n",
      "Song 100: \"Red (Original Demo Recording)\"\n",
      "\n",
      "Reached user-specified song limit (100).\n",
      "Done. Found 100 songs.\n",
      "Wrote `Lyrics_TaylorSwift.json`\n"
     ]
    }
   ],
   "source": [
    "for artist_name in artist_names:\n",
    "    artist = api.search_artist(artist_name, max_songs=NUM_OF_SONGS)\n",
    "    artist.save_lyrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the Data\n",
    "Remove excess JSON data and write to a new file, just with the lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/Lyrics_JamesTaylor.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f3caa6c0f0af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0ma_mod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'Lyrics_{a_mod}.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./data/{filename}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0msong_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/Lyrics_JamesTaylor.json'"
     ]
    }
   ],
   "source": [
    "for artist in tqdm(artist_names):\n",
    "    a_mod = artist.replace(' ', '')\n",
    "    filename = f'Lyrics_{a_mod}.json'\n",
    "    with open(f'./data/{filename}') as f:\n",
    "        data = json.load(f)\n",
    "        song_obj = {}\n",
    "        song_obj[artist] = []\n",
    "        for song in data['songs']:\n",
    "            song_obj[artist].append(song['lyrics'])\n",
    "        with open(f'./data/cleaned/{artist}.json', 'w') as outfile:\n",
    "            json.dump(song_obj, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract, tokenize, and one hot encode data to X, Y vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(971, 100)\n",
      "(971, 10)\n"
     ]
    }
   ],
   "source": [
    "# get basic X, Y sets for training + testing\n",
    "# X is song lyrics\n",
    "# Y is the one-hot encoding of the artists\n",
    "X = []\n",
    "Y = []\n",
    "NUM_OF_ARTISTS = len(list(os.listdir('./data/cleaned'))) - 1\n",
    "artist_index_map = {}\n",
    "\n",
    "def clean_word(word):\n",
    "    word = word.replace('\\n', '')\n",
    "    word = word.replace('[', '')\n",
    "    word = word.replace(']', '')\n",
    "    word = word.replace(':', '')\n",
    "    return word\n",
    "\n",
    "index = 0\n",
    "for filename in os.listdir('./data/cleaned'):\n",
    "    with open(f'./data/cleaned/{filename}') as file:\n",
    "        if filename == '.DS_Store': continue\n",
    "        data = json.load(file)[filename.replace('.json', '')]\n",
    "        if len(data) == 100:\n",
    "            for song in data:\n",
    "                \n",
    "                X.append(song)\n",
    "                # one hot encode artist\n",
    "                one_h = np.zeros(NUM_OF_ARTISTS)\n",
    "                one_h[index] = 1\n",
    "                artist_index_map[index] = filename.replace('.json', '')\n",
    "                Y.append(one_h)\n",
    "            index += 1\n",
    "\n",
    "# create encoding of words\n",
    "# i.e. map words to numbers\n",
    "big_word_list = {}\n",
    "for song in X:\n",
    "    for line in song.split('\\n'):\n",
    "        for word in line.split(' '):\n",
    "            word = clean_word(word)\n",
    "            if word not in big_word_list.keys():\n",
    "                if (len(big_word_list.keys()) == 0):\n",
    "                    big_word_list[word] = 1\n",
    "                else:\n",
    "                    big_word_list[word] = len(big_word_list) + 1\n",
    "                \n",
    "# tokenize the songs\n",
    "# so we are mapping each word to it's key in the big_word_list\n",
    "token_x = []\n",
    "for song in X:\n",
    "    new_song = []\n",
    "    for line in song.split('\\n'):\n",
    "        for word in line.split(' '):\n",
    "            word = clean_word(word)\n",
    "            new_song.append(big_word_list[word])\n",
    "    token_x.append(np.array(new_song))\n",
    "X = token_x\n",
    "\n",
    "# cutting off lyrics min 100 words\n",
    "# to normalize network input\n",
    "cutoff = 100\n",
    "index = 0\n",
    "new_x = []\n",
    "new_y = []\n",
    "for song in X:\n",
    "    if (len(song) >= cutoff):\n",
    "        new_x.append(song)\n",
    "        new_y.append(Y[index])\n",
    "    index += 1\n",
    "X = new_x\n",
    "Y = new_y\n",
    "\n",
    "# trim all of the lyrics to 100 words max,\n",
    "# so the network input in normalized\n",
    "trimmed = []\n",
    "for song in X:\n",
    "    song = song[:100]\n",
    "    trimmed.append(song)\n",
    "X = trimmed\n",
    "\n",
    "# convert to numpy arrays for keras\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "X, Y = shuffle(X, Y, random_state=0)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 100)\n",
      "(800, 10)\n",
      "(171, 100)\n",
      "(171, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train = X[:800]\n",
    "y_train = Y[:800]\n",
    "\n",
    "X_test = X[800:]\n",
    "y_test = Y[800:]\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def artist_from_output(out):\n",
    "    index = np.argmax(out)\n",
    "    return artist_index_map[index]\n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for word in text:\n",
    "        if word in big_word_list.keys():\n",
    "            tokens.append(big_word_list[word])\n",
    "        else:\n",
    "            tokens.append(len(big_word_list) + 1)\n",
    "            big_word_list[word] = len(big_word_list) + 1\n",
    "    tokens = np.array(tokens)\n",
    "    return tokens\n",
    "\n",
    "def text_from_tokens(tokens):\n",
    "    text = []\n",
    "    for token in tokens:\n",
    "        index = 0\n",
    "        for entry in big_word_list.values():\n",
    "            if token == entry:\n",
    "                text.append(list(big_word_list.keys())[index])\n",
    "            index += 1\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model, train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_61 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 250)               25250     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1000)              251000    \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 791,860\n",
      "Trainable params: 791,860\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(100, input_shape=(100,)),\n",
    "    Activation('softmax'),\n",
    "    Dense(250),\n",
    "    Activation('softmax'),\n",
    "    Dense(1000),\n",
    "    Activation('softmax'),\n",
    "    Dense(500),\n",
    "    Activation('softmax'),\n",
    "    Dense(NUM_OF_ARTISTS)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 171 samples\n",
      "Epoch 1/1000\n",
      "800/800 [==============================] - 0s 472us/step - loss: 0.0964 - accuracy: 0.1063 - val_loss: 0.0941 - val_accuracy: 0.0877\n",
      "Epoch 2/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 0.0930 - accuracy: 0.1037 - val_loss: 0.0920 - val_accuracy: 0.0877\n",
      "Epoch 3/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 0.0914 - accuracy: 0.1063 - val_loss: 0.0909 - val_accuracy: 0.0877\n",
      "Epoch 4/1000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 0.0906 - accuracy: 0.0950 - val_loss: 0.0904 - val_accuracy: 0.0877\n",
      "Epoch 5/1000\n",
      "800/800 [==============================] - 0s 287us/step - loss: 0.0902 - accuracy: 0.1075 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 6/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 0.0901 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 7/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 8/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 9/1000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 10/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 11/1000\n",
      "800/800 [==============================] - 0s 278us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 12/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 13/1000\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 14/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 15/1000\n",
      "800/800 [==============================] - 0s 264us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 16/1000\n",
      "800/800 [==============================] - 0s 252us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 17/1000\n",
      "800/800 [==============================] - 0s 255us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 18/1000\n",
      "800/800 [==============================] - 0s 270us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 19/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 20/1000\n",
      "800/800 [==============================] - 0s 265us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 21/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 22/1000\n",
      "800/800 [==============================] - 0s 266us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 23/1000\n",
      "800/800 [==============================] - 0s 265us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 24/1000\n",
      "800/800 [==============================] - 0s 276us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 25/1000\n",
      "800/800 [==============================] - 0s 327us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 26/1000\n",
      "800/800 [==============================] - 0s 263us/step - loss: 0.0900 - accuracy: 0.0825 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 27/1000\n",
      "800/800 [==============================] - 0s 271us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 28/1000\n",
      "800/800 [==============================] - 0s 274us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 29/1000\n",
      "800/800 [==============================] - 0s 313us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 30/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 31/1000\n",
      "800/800 [==============================] - 0s 265us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 32/1000\n",
      "800/800 [==============================] - 0s 279us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 33/1000\n",
      "800/800 [==============================] - 0s 325us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 34/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 35/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 36/1000\n",
      "800/800 [==============================] - 0s 261us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 37/1000\n",
      "800/800 [==============================] - 0s 225us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 38/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 39/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 40/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 41/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 42/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 43/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0900 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 44/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 45/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 46/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0900 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 47/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 48/1000\n",
      "800/800 [==============================] - 0s 219us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 49/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 50/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 51/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.0850 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 52/1000\n",
      "800/800 [==============================] - 0s 300us/step - loss: 0.0900 - accuracy: 0.0850 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 53/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 54/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1100 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 55/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 57/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 58/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 59/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 60/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 61/1000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 62/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.0838 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 63/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 64/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 65/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 66/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 67/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 68/1000\n",
      "800/800 [==============================] - 0s 219us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 69/1000\n",
      "800/800 [==============================] - 0s 224us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 70/1000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 71/1000\n",
      "800/800 [==============================] - 0s 220us/step - loss: 0.0900 - accuracy: 0.0825 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 72/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.0838 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 73/1000\n",
      "800/800 [==============================] - 0s 212us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 74/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 75/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 76/1000\n",
      "800/800 [==============================] - 0s 214us/step - loss: 0.0900 - accuracy: 0.0900 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 77/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 78/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 79/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 80/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 81/1000\n",
      "800/800 [==============================] - 0s 224us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 82/1000\n",
      "800/800 [==============================] - 0s 261us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 83/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 84/1000\n",
      "800/800 [==============================] - 0s 219us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 85/1000\n",
      "800/800 [==============================] - 0s 216us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 86/1000\n",
      "800/800 [==============================] - 0s 226us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 87/1000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 88/1000\n",
      "800/800 [==============================] - 0s 239us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 89/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 90/1000\n",
      "800/800 [==============================] - 0s 227us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 91/1000\n",
      "800/800 [==============================] - 0s 224us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 92/1000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 0.0900 - accuracy: 0.0850 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 93/1000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 94/1000\n",
      "800/800 [==============================] - 0s 224us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 95/1000\n",
      "800/800 [==============================] - 0s 236us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 96/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 97/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 98/1000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 99/1000\n",
      "800/800 [==============================] - 0s 225us/step - loss: 0.0900 - accuracy: 0.0787 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 100/1000\n",
      "800/800 [==============================] - 0s 231us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 101/1000\n",
      "800/800 [==============================] - 0s 259us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 102/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 103/1000\n",
      "800/800 [==============================] - 0s 226us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 104/1000\n",
      "800/800 [==============================] - 0s 220us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 105/1000\n",
      "800/800 [==============================] - 0s 226us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 106/1000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 107/1000\n",
      "800/800 [==============================] - 0s 239us/step - loss: 0.0900 - accuracy: 0.0850 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 108/1000\n",
      "800/800 [==============================] - 0s 231us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 109/1000\n",
      "800/800 [==============================] - 0s 228us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 110/1000\n",
      "800/800 [==============================] - 0s 227us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 111/1000\n",
      "800/800 [==============================] - 0s 227us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/1000\n",
      "800/800 [==============================] - 0s 219us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 113/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 114/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 115/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 116/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 117/1000\n",
      "800/800 [==============================] - 0s 183us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 118/1000\n",
      "800/800 [==============================] - 0s 184us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 119/1000\n",
      "800/800 [==============================] - 0s 182us/step - loss: 0.0900 - accuracy: 0.0787 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 120/1000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 121/1000\n",
      "800/800 [==============================] - 0s 186us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 122/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 123/1000\n",
      "800/800 [==============================] - 0s 179us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 124/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 125/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 126/1000\n",
      "800/800 [==============================] - 0s 185us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 127/1000\n",
      "800/800 [==============================] - 0s 181us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 128/1000\n",
      "800/800 [==============================] - 0s 184us/step - loss: 0.0900 - accuracy: 0.0825 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 129/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 130/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0850 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 131/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 132/1000\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 133/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 134/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 135/1000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 136/1000\n",
      "800/800 [==============================] - 0s 227us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 137/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 138/1000\n",
      "800/800 [==============================] - 0s 216us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 139/1000\n",
      "800/800 [==============================] - 0s 217us/step - loss: 0.0900 - accuracy: 0.0862 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 140/1000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 141/1000\n",
      "800/800 [==============================] - 0s 212us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 142/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 143/1000\n",
      "800/800 [==============================] - 0s 220us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 144/1000\n",
      "800/800 [==============================] - 0s 236us/step - loss: 0.0900 - accuracy: 0.0850 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 145/1000\n",
      "800/800 [==============================] - 0s 225us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 146/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.1100 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 147/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 148/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 149/1000\n",
      "800/800 [==============================] - 0s 221us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 150/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 0.0900 - accuracy: 0.0850 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 151/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1100 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 152/1000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 153/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 154/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 155/1000\n",
      "800/800 [==============================] - 0s 263us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 156/1000\n",
      "800/800 [==============================] - 0s 233us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 157/1000\n",
      "800/800 [==============================] - 0s 212us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 158/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 159/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 160/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 0.0900 - accuracy: 0.0838 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 161/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 162/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 163/1000\n",
      "800/800 [==============================] - 0s 216us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 164/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.0775 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 165/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 166/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 167/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 212us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 168/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 169/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 170/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 171/1000\n",
      "800/800 [==============================] - 0s 226us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 172/1000\n",
      "800/800 [==============================] - 0s 232us/step - loss: 0.0900 - accuracy: 0.0887 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 173/1000\n",
      "800/800 [==============================] - 0s 222us/step - loss: 0.0900 - accuracy: 0.0850 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 174/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 175/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 176/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 177/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 178/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 179/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 180/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 181/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 182/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 183/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 184/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 185/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 186/1000\n",
      "800/800 [==============================] - 0s 226us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 187/1000\n",
      "800/800 [==============================] - 0s 221us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 188/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 189/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 190/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 191/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 192/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 193/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0862 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 194/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 195/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 196/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 197/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 198/1000\n",
      "800/800 [==============================] - 0s 226us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 199/1000\n",
      "800/800 [==============================] - 0s 222us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 200/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0838 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 201/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 202/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 203/1000\n",
      "800/800 [==============================] - 0s 225us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 204/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 205/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 206/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 207/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 208/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 209/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 210/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 211/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.0825 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 212/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 213/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 214/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 215/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 216/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 217/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 218/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0862 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 219/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 220/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 221/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 222/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 223/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 224/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 225/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 226/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 227/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 228/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 229/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 230/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 231/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.0862 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 232/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 233/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 234/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 235/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 236/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 237/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 238/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 239/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 240/1000\n",
      "800/800 [==============================] - 0s 234us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 241/1000\n",
      "800/800 [==============================] - 0s 280us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 242/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 243/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 244/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 245/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 246/1000\n",
      "800/800 [==============================] - 0s 214us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 247/1000\n",
      "800/800 [==============================] - 0s 214us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 248/1000\n",
      "800/800 [==============================] - 0s 239us/step - loss: 0.0900 - accuracy: 0.0838 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 249/1000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 0.0900 - accuracy: 0.0750 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 250/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 251/1000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 252/1000\n",
      "800/800 [==============================] - 0s 220us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 253/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 254/1000\n",
      "800/800 [==============================] - 0s 217us/step - loss: 0.0900 - accuracy: 0.0850 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 255/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 256/1000\n",
      "800/800 [==============================] - 0s 222us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 257/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 0.0900 - accuracy: 0.0887 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 258/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 259/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 260/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 261/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 262/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0825 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 263/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 264/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 265/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 266/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 267/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 268/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 269/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 270/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 271/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 272/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 273/1000\n",
      "800/800 [==============================] - 0s 215us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 274/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 275/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 276/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 277/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 278/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 279/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 280/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 281/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 282/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 283/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 284/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 285/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0900 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 286/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 287/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 288/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 289/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 290/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 291/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 292/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 293/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 294/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 295/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 296/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.0862 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 297/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 298/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.0900 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 299/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 300/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 301/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 302/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 303/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 304/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 305/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 306/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 307/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 308/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 309/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 310/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 311/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0825 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 312/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 313/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 314/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 315/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 316/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.0862 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 317/1000\n",
      "800/800 [==============================] - 0s 212us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 318/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 319/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 320/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 321/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 322/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 323/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 324/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 325/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 326/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 0.0900 - accuracy: 0.1100 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 327/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 328/1000\n",
      "800/800 [==============================] - 0s 212us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 329/1000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 330/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 331/1000\n",
      "800/800 [==============================] - 0s 228us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 332/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 333/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 334/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 335/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 336/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 337/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 338/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 339/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 340/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 341/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 342/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 343/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 344/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 345/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 346/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 347/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 348/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 349/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0900 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 350/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 351/1000\n",
      "800/800 [==============================] - 0s 188us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 352/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 353/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 354/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.1112 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 355/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 356/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 357/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 358/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 359/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 360/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 361/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 362/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 363/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 364/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 365/1000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 366/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 367/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 368/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 369/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 370/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0838 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 371/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 372/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 373/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 374/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 375/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 376/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 377/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 378/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 379/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 380/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 381/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.0900 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 382/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 383/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.0812 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 384/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 385/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 386/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 387/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 388/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 389/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.0825 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 390/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 391/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 392/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 393/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 394/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 395/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 396/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 397/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 398/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 399/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.0862 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 400/1000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 401/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 402/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 403/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 404/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 405/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 406/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 407/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 408/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 409/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 410/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 411/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 412/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 0.0900 - accuracy: 0.0825 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 413/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 414/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 415/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.0787 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 416/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 417/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 418/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 419/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 420/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 421/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 422/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 423/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 424/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 425/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.0887 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 426/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 427/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 428/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 429/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0812 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 430/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 431/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 432/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0887 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 433/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 434/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 435/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 436/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 437/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 438/1000\n",
      "800/800 [==============================] - 0s 187us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 439/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 440/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 441/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 442/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 223us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 443/1000\n",
      "800/800 [==============================] - 0s 220us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 444/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 445/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 446/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 447/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 448/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 449/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 450/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 0.0900 - accuracy: 0.0812 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 451/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 452/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 453/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 454/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 455/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 456/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 457/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 458/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 459/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 460/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 461/1000\n",
      "800/800 [==============================] - 0s 216us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 462/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 463/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 464/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 465/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 466/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 467/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 468/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 469/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 470/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 471/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 472/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 473/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 474/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 475/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 476/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 477/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 478/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 479/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 480/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 481/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 482/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 483/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 484/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 485/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 486/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 487/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 488/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 489/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 490/1000\n",
      "800/800 [==============================] - 0s 189us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 491/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 492/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 493/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 494/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 495/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 496/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 498/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 499/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 500/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 501/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 502/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.0862 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 503/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 504/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.0900 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 505/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 506/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 507/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 508/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 509/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 510/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 511/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 512/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 513/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 514/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 515/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 516/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 517/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 518/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 519/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 520/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 521/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 522/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 523/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 0.0900 - accuracy: 0.0900 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 524/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 525/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 526/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 527/1000\n",
      "800/800 [==============================] - 0s 190us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 528/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 529/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.0850 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 530/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 531/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 532/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 533/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 534/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 535/1000\n",
      "800/800 [==============================] - 0s 192us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 536/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 537/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 538/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 539/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 540/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 541/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 542/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 543/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 544/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 545/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 546/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 547/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 548/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 549/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 550/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 551/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 552/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 553/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 554/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.0862 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 555/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 556/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0887 - val_loss: 0.0901 - val_accuracy: 0.1111\n",
      "Epoch 557/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 558/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 559/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 560/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 561/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 562/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 563/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 564/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 565/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 566/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 567/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 568/1000\n",
      "800/800 [==============================] - 0s 191us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 569/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.1100 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 570/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 571/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 572/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.0887 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 573/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 574/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 575/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 576/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 577/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 578/1000\n",
      "800/800 [==============================] - 0s 196us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 579/1000\n",
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 580/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 581/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 582/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 583/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 584/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 585/1000\n",
      "800/800 [==============================] - 0s 214us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 586/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 587/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 588/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.0862 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 589/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 590/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 591/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 592/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0900 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 593/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 594/1000\n",
      "800/800 [==============================] - 0s 234us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 595/1000\n",
      "800/800 [==============================] - 0s 217us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 596/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 597/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 598/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 599/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 600/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 601/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 602/1000\n",
      "800/800 [==============================] - 0s 237us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 603/1000\n",
      "800/800 [==============================] - 0s 233us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 604/1000\n",
      "800/800 [==============================] - 0s 237us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 605/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 606/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 0.0900 - accuracy: 0.0862 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 607/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 222us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 608/1000\n",
      "800/800 [==============================] - 0s 217us/step - loss: 0.0900 - accuracy: 0.0900 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 609/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 610/1000\n",
      "800/800 [==============================] - 0s 310us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 611/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0900 - accuracy: 0.0850 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 612/1000\n",
      "800/800 [==============================] - 0s 297us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 613/1000\n",
      "800/800 [==============================] - 0s 289us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 614/1000\n",
      "800/800 [==============================] - 0s 230us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 615/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 616/1000\n",
      "800/800 [==============================] - 0s 232us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 617/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 618/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 619/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 620/1000\n",
      "800/800 [==============================] - 0s 261us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 621/1000\n",
      "800/800 [==============================] - 0s 290us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 622/1000\n",
      "800/800 [==============================] - 0s 285us/step - loss: 0.0900 - accuracy: 0.0862 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 623/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 0.0900 - accuracy: 0.0900 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 624/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 625/1000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 626/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 627/1000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 628/1000\n",
      "800/800 [==============================] - 0s 234us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 629/1000\n",
      "800/800 [==============================] - 0s 214us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 630/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 631/1000\n",
      "800/800 [==============================] - 0s 248us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 632/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 633/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 634/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 0.0900 - accuracy: 0.0825 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 635/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 636/1000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 0.0900 - accuracy: 0.0887 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 637/1000\n",
      "800/800 [==============================] - 0s 250us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 638/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 639/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 640/1000\n",
      "800/800 [==============================] - 0s 233us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 641/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 642/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 643/1000\n",
      "800/800 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.08 - 0s 248us/step - loss: 0.0900 - accuracy: 0.0838 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 644/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 645/1000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 646/1000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 0.0900 - accuracy: 0.0850 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 647/1000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 0.0900 - accuracy: 0.0900 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 648/1000\n",
      "800/800 [==============================] - 0s 230us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 649/1000\n",
      "800/800 [==============================] - 0s 215us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 650/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 651/1000\n",
      "800/800 [==============================] - 0s 255us/step - loss: 0.0900 - accuracy: 0.0887 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 652/1000\n",
      "800/800 [==============================] - 0s 256us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 653/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 654/1000\n",
      "800/800 [==============================] - 0s 241us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 655/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 656/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 657/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 658/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 659/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 660/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 661/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 662/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 206us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 663/1000\n",
      "800/800 [==============================] - 0s 235us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 664/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 665/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 666/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 667/1000\n",
      "800/800 [==============================] - 0s 230us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 668/1000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 0.0900 - accuracy: 0.0825 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 669/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 670/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 671/1000\n",
      "800/800 [==============================] - 0s 237us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 672/1000\n",
      "800/800 [==============================] - 0s 253us/step - loss: 0.0900 - accuracy: 0.0787 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 673/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 0.0900 - accuracy: 0.0800 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 674/1000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 675/1000\n",
      "800/800 [==============================] - 0s 235us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 676/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 677/1000\n",
      "800/800 [==============================] - 0s 233us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 678/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 679/1000\n",
      "800/800 [==============================] - 0s 195us/step - loss: 0.0900 - accuracy: 0.0850 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 680/1000\n",
      "800/800 [==============================] - 0s 215us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 681/1000\n",
      "800/800 [==============================] - 0s 252us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 682/1000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 0.0900 - accuracy: 0.0900 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 683/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 684/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 685/1000\n",
      "800/800 [==============================] - 0s 229us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 686/1000\n",
      "800/800 [==============================] - 0s 193us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 687/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 688/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 689/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 690/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 691/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 692/1000\n",
      "800/800 [==============================] - 0s 238us/step - loss: 0.0900 - accuracy: 0.0850 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 693/1000\n",
      "800/800 [==============================] - 0s 244us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 694/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 0.0900 - accuracy: 0.0812 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 695/1000\n",
      "800/800 [==============================] - 0s 230us/step - loss: 0.0900 - accuracy: 0.1000 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 696/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 697/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 698/1000\n",
      "800/800 [==============================] - 0s 222us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 699/1000\n",
      "800/800 [==============================] - 0s 212us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 700/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 701/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 702/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.0838 - val_loss: 0.0902 - val_accuracy: 0.0877\n",
      "Epoch 703/1000\n",
      "800/800 [==============================] - 0s 204us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 704/1000\n",
      "800/800 [==============================] - 0s 197us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 705/1000\n",
      "800/800 [==============================] - 0s 208us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 706/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 707/1000\n",
      "800/800 [==============================] - 0s 212us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 708/1000\n",
      "800/800 [==============================] - 0s 198us/step - loss: 0.0900 - accuracy: 0.0887 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 709/1000\n",
      "800/800 [==============================] - 0s 202us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 710/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 711/1000\n",
      "800/800 [==============================] - 0s 203us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 712/1000\n",
      "800/800 [==============================] - 0s 194us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 713/1000\n",
      "800/800 [==============================] - 0s 213us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 714/1000\n",
      "800/800 [==============================] - 0s 258us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 715/1000\n",
      "800/800 [==============================] - 0s 234us/step - loss: 0.0900 - accuracy: 0.0900 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 716/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 717/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 246us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 718/1000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 719/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.0838 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 720/1000\n",
      "800/800 [==============================] - 0s 221us/step - loss: 0.0900 - accuracy: 0.0887 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 721/1000\n",
      "800/800 [==============================] - 0s 200us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 722/1000\n",
      "800/800 [==============================] - 0s 239us/step - loss: 0.0900 - accuracy: 0.0862 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 723/1000\n",
      "800/800 [==============================] - 0s 222us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 724/1000\n",
      "800/800 [==============================] - 0s 201us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 725/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 726/1000\n",
      "800/800 [==============================] - 0s 199us/step - loss: 0.0900 - accuracy: 0.0887 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 727/1000\n",
      "800/800 [==============================] - 0s 212us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 728/1000\n",
      "800/800 [==============================] - 0s 225us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 729/1000\n",
      "800/800 [==============================] - 0s 210us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 730/1000\n",
      "800/800 [==============================] - 0s 265us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 731/1000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 732/1000\n",
      "800/800 [==============================] - 0s 217us/step - loss: 0.0900 - accuracy: 0.0925 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 733/1000\n",
      "800/800 [==============================] - 0s 215us/step - loss: 0.0900 - accuracy: 0.1063 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 734/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.0900 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 735/1000\n",
      "800/800 [==============================] - 0s 209us/step - loss: 0.0900 - accuracy: 0.0887 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 736/1000\n",
      "800/800 [==============================] - 0s 205us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 737/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 738/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 739/1000\n",
      "800/800 [==============================] - 0s 220us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 740/1000\n",
      "800/800 [==============================] - 0s 212us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 741/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 742/1000\n",
      "800/800 [==============================] - 0s 211us/step - loss: 0.0900 - accuracy: 0.0825 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 743/1000\n",
      "800/800 [==============================] - 0s 284us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 744/1000\n",
      "800/800 [==============================] - 0s 303us/step - loss: 0.0900 - accuracy: 0.0750 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 745/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 746/1000\n",
      "800/800 [==============================] - 0s 226us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 747/1000\n",
      "800/800 [==============================] - 0s 207us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 748/1000\n",
      "800/800 [==============================] - 0s 224us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 749/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 750/1000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 751/1000\n",
      "800/800 [==============================] - 0s 273us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 752/1000\n",
      "800/800 [==============================] - 0s 251us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 753/1000\n",
      "800/800 [==============================] - 0s 271us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 754/1000\n",
      "800/800 [==============================] - 0s 245us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 755/1000\n",
      "800/800 [==============================] - 0s 247us/step - loss: 0.0900 - accuracy: 0.0825 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 756/1000\n",
      "800/800 [==============================] - 0s 218us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 757/1000\n",
      "800/800 [==============================] - 0s 227us/step - loss: 0.0900 - accuracy: 0.0975 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 758/1000\n",
      "800/800 [==============================] - 0s 223us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 759/1000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 0.0900 - accuracy: 0.1050 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 760/1000\n",
      "800/800 [==============================] - 0s 254us/step - loss: 0.0900 - accuracy: 0.1013 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 761/1000\n",
      "800/800 [==============================] - 0s 237us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 762/1000\n",
      "800/800 [==============================] - 0s 283us/step - loss: 0.0900 - accuracy: 0.0988 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 763/1000\n",
      "800/800 [==============================] - 0s 302us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 764/1000\n",
      "800/800 [==============================] - 0s 226us/step - loss: 0.0900 - accuracy: 0.0875 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 765/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 0.0900 - accuracy: 0.0950 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 766/1000\n",
      "800/800 [==============================] - 0s 242us/step - loss: 0.0900 - accuracy: 0.1025 - val_loss: 0.0901 - val_accuracy: 0.0702\n",
      "Epoch 767/1000\n",
      "800/800 [==============================] - 0s 257us/step - loss: 0.0900 - accuracy: 0.1075 - val_loss: 0.0901 - val_accuracy: 0.0936\n",
      "Epoch 768/1000\n",
      "800/800 [==============================] - 0s 243us/step - loss: 0.0900 - accuracy: 0.1037 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 769/1000\n",
      "800/800 [==============================] - 0s 246us/step - loss: 0.0900 - accuracy: 0.0913 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 770/1000\n",
      "800/800 [==============================] - 0s 232us/step - loss: 0.0900 - accuracy: 0.0938 - val_loss: 0.0901 - val_accuracy: 0.0877\n",
      "Epoch 771/1000\n",
      "800/800 [==============================] - 0s 240us/step - loss: 0.0900 - accuracy: 0.0962 - val_loss: 0.0902 - val_accuracy: 0.0702\n",
      "Epoch 772/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 0s 231us/step - loss: 0.0900 - accuracy: 0.1088 - val_loss: 0.0902 - val_accuracy: 0.0936\n",
      "Epoch 773/1000\n",
      "320/800 [===========>..................] - ETA: 0s - loss: 0.0901 - accuracy: 0.0812"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-139-e686e90f587b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         batch_size=64)\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=1000,\n",
    "        verbose=True,\n",
    "        validation_data=(X_test, y_test),\n",
    "        batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johnny Cash\n",
      "['Verse', '1', 'Six', 'foot', 'six', 'he', 'stood', 'on', 'the', 'ground']\n",
      "J. Cole\n",
      "['Verse', '1', 'Yeah', 'Yeah', '', 'Look,', 'I', 'just', 'shed', 'tears']\n",
      "Taylor Swift\n",
      "['Verse', '1', 'I', 'never', 'trust', 'a', 'narcissist,', 'but', 'they', 'love']\n",
      "Lil Wayne\n",
      "['Intro', 'Kendrick', 'Lamar', 'I', 'got', 'a', 'story', 'to', 'tell,', 'you']\n",
      "Bob Dylan\n",
      "['Verse', '1', 'Buckets', 'of', 'rain', 'Buckets', 'of', 'tears', 'Got', 'all']\n",
      "Lil Wayne\n",
      "['Chorus', 'Why', 'me?', 'Oh', 'why,', 'oh', 'why,', 'oh', 'why', 'me?']\n",
      "Lil Wayne\n",
      "['Intro', 'Lil', 'Wayne', 'Young', 'Money!', 'Yeah', 'Four', 'Ahem!', '', 'Verse']\n",
      "Johnny Cash\n",
      "['Verse', 'From', 'his', 'hands', 'it', 'came', 'down', 'From', 'the', 'side']\n",
      "Van Morrison\n",
      "[\"Haven't\", 'heard', 'your', 'voice', 'in', 'quite', 'a', 'while', \"Haven't\", 'seen']\n",
      "Fleetwood Mac\n",
      "['Verse', '1', \"It's\", 'not', 'that', 'funny', 'is', 'it', 'When', 'you']\n",
      "Taylor Swift\n",
      "['Verse', '1', 'It', 'was', 'so', 'nice', 'throwing', 'big', 'parties', 'Jump']\n",
      "Johnny Cash\n",
      "['Verse', '1', 'Belinda', 'was', 'mine', 'until', 'the', 'time', 'that', 'I']\n",
      "Fleetwood Mac\n",
      "['And', 'the', 'planets', 'of', 'the', 'universe', 'go', 'their', 'way', 'Not']\n",
      "Lil Wayne\n",
      "['Verse', '1', 'Camo', 'shorts', 'and', 'Bubba', 'Kush', 'We', 'can', 'talk']\n",
      "Lil Wayne\n",
      "['Intro', 'Yeah,', 'yeah', 'Mmm...', '', 'Chorus', 'I', \"don't\", 'know', 'who']\n",
      "Lil Wayne\n",
      "['Verse', 'One', 'Uh,', \"I'm\", 'flying', 'private', 'through', 'Cloud', '9', 'Yeah,']\n",
      "Lil Wayne\n",
      "['Verse', '1', 'Lil', 'Wayne', 'Tell', 'me', 'something', 'I', \"don't\", 'know']\n",
      "Van Morrison\n",
      "['Chorus', 'Well,', \"I'm\", 'caught', 'one', 'more', 'time', 'Up', 'on', 'Cyprus']\n",
      "Beyoncé\n",
      "['Intro', 'All', 'the', 'ladies,', 'if', 'you', 'feel', 'me,', 'help', 'me']\n",
      "Lil Wayne\n",
      "['Chorus', 'Thomas', 'Troelsen', 'You', 'cannot', 'break', 'down', 'what', \"can't\", 'be']\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(artist_from_output(Y[i]))\n",
    "    print(text_from_tokens(X[i][:10]))\n",
    "\n",
    "# inp = tokenize_text(sample_text)\n",
    "# print(inp.shape)\n",
    "# print(get_artist_from_output(Y[2]))\n",
    "# x_val = np.array([X[2]])\n",
    "\n",
    "# output = model.predict(x_val)\n",
    "# get_artist_from_output(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9000\n",
      "Testing Accuracy:  0.9000\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_train, y_train, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAFACAYAAABOYuFgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdeXhTZdrH8W+W7hu0oS0FBKRQ2RXKIiBQWjYBB3UQHBURFRl2FwQZZNxQxLIJOiBWcAd0GB1EAasgSodVeFkKSimilUKhZe2e5rx/hIYmTZq0Tdqk3J/rmms4J2d5TlJPf31yn+dRKYqiIIQQQgghhDBR13YDhBBCCCGEcDcSkoUQQgghhLAgIVkIIYQQQggLEpKFEEIIIYSwICFZCCGEEEIICxKShRBCCCGEsCAhuRYdO3YMlUrF3r17K7VfZGQkiYmJLmpVzamJ6ygoKEClUvH5559X6ryjRo1i6NCh1T7/pk2bUKlUnD9/vtrHEkLUDXLvl3u/MzmrzaI8bW03wJ2pVKoKX2/atCm//fZblY/fsmVLMjMz0el0ldrv0KFDBAQEVPm8NzpXvH96vR4vLy8+/fRTRo0aZVrfr18/MjMzCQsLc+r5hBCuI/f+uknu/aKyJCRXIDMz0/TvlJQU7r33Xn7++WcaNmwIgEajsbpfUVER3t7edo+v0WiIjIysdLsaNGhQ6X3EdTX5/nl7e1fpM65LHP3vQQh3Iff+uknu/aKypNyiApGRkab/hYaGAsb/yErXlf4HFxkZyYsvvsi4ceMIDQ2lf//+ACQmJtKhQwcCAgKIioriwQcfJCsry3R8y6/cSpfXr1/P4MGD8ff3Jzo6mk8++aRcu8p+ZRQZGcncuXOZOHEi9erVIzIykhkzZmAwGEzb5ObmMnbsWIKDgwkNDWXKlCk8/fTTtGvXrsL3wN41lH6ltHXrVnr27Imfnx/t2rUjOTnZ7Dj79u2jW7du+Pj4EBMTwxdffFHhebOzs/Hx8WH9+vVm63/77TfUajU//fQTAO+//z5dunQhODiYBg0acNddd3HixIkKj235/p07d457770Xf39/IiMjeemll8rt8/XXX9O7d29CQ0OpV68e/fr14+effza93rhxYwDuv/9+VCoVvr6+Zu9P2a/cfvrpJ3r16oWvry+hoaGMHj2a7Oxs0+szZ86kXbt2fPbZZ7Rq1YrAwEDi4+M5efJkhddlr40Aly9fZtKkSTRq1AgfHx9uvvlms/ciMzOT0aNHEx4ejq+vL7fccgsfffSRzWvR6/WoVCrWrFkDXP8ZXrt2LQMGDMDf35+5c+dSXFzMo48+ys0334yfnx8tWrTgn//8J8XFxWbt++abb+jRowf+/v7Uq1ePuLg4fv/9dzZt2oS3tzdnz5412/6dd94hLCyMwsLCCt8bISpD7v1y7y/lCfd+S4qi8Nprr9GsWTO8vb2Jjo7mrbfeMtvm888/p2PHjvj7+1O/fn1uv/12Dh8+DEBhYSFTpkwx/Z6Iiori4YcfrlQb6goJyU6yYMECmjVrxq5du1ixYgVg/Mpu8eLFHD58mM8++4xff/2Vhx56yO6xZsyYweOPP87BgwcZPnw4Y8aMsfvV3oIFC7j55pvZs2cPCxcuJDExkU8//dT0+pNPPsnmzZtZs2YNKSkpeHl58e6779pti6PX8Mwzz/DCCy/wf//3f3Ts2JH77ruPK1euAHDlyhUGDx5Mw4YN2bNnD0lJSbz88stcvHjR5nnDwsIYMmQIH374odn6Dz74gObNm9OrVy/A2HPz4osvsn//fjZt2kRxcTF33XUXer3e7rWVGj16NEeOHOGbb74hOTmZw4cP8/XXX5ttk5uby9SpU9m5cyc//fQTjRs3ZtCgQVy6dAmA/fv3A7B8+XIyMzM5deqU1XP98ccfDBw4kOjoaPbt28d//vMf9uzZY/Y1HcCpU6dYvXo1a9eu5ccff+TcuXOMGzeuwuuw10aDwcCgQYPYsmULK1as4OjRoyQlJZlCwNWrV7njjjs4duwYa9asITU1lUWLFuHj4+Pwe1nq2WefZezYsRw5coRHHnmEkpISGjVqxJo1azh69CiJiYm8/fbbZr+wvv76a4YOHUrPnj3ZuXMnKSkp3H///RQXFzNgwAAaNWrE6tWrzc6zcuVKRo8eXaU2CuEMcu+Xez/U7r3f0sKFC3nllVf45z//yZEjR5g2bRpPPvkkH3/8MQC///47o0aNMt2jd+zYwYQJE0zfkCxYsIANGzbw6aefcvz4cb744gtiY2Mr1YY6QxEO2bp1qwIof/zxR7nXIiIilDvvvNPuMVJSUhRAOX/+vKIoinL06FEFUPbs2WO2/NZbb5n2KSwsVLy9vZXVq1ebne+NN94wWx4xYoTZufr27auMGTNGURRFycnJUbRarfLRRx+ZbdOxY0elbdu2dttd0TV88803CqBs3LjRtM1vv/2mAMq2bdsURVGUpUuXKiEhIcrly5dN2+zZs0cBzK7D0n/+8x/F29vbdC5FUZTo6GjlhRdesLnP6dOnFUDZu3evoiiKkp+frwDKZ599Ztqm7Pt36NAhBVC2b99uej0vL09p0KCBMmTIEJvnKS4uVvz9/ZXPP//ctAwon376qdl2pe/PuXPnFEVRlGeeeUZp3ry5UlxcbNpm586dCqDs2rVLURRFmTFjhuLt7a3k5OSYtlm9erWi1WoVvV5vs0322vjVV18pgHLw4EGr2y9btkwJCAhQzpw5Y/V1y2uxdt2lP8Pz58+3275XX31VadeunWk5NjZWuffee21uP3fuXCU6OloxGAyKoijKgQMHFEA5cuSI3XMJUVVy77d+DXLvd597/8iRI83arNPplOeff95sm/HjxyutW7dWFMX4WapUKuX06dNWjzdu3Dhl0KBBpnvtjUx6kp2ka9eu5dYlJyfTv39/mjRpQlBQEAkJCQA2/9Isdeutt5r+7e3tjU6nK/c1c0X7AERFRZn2+fXXX9Hr9XTv3t1sm9tvv73CY1bmGsqePyoqCsB0/tTUVNq3b09QUJBpm86dO5u+lrJlyJAhBAcHs3btWsBYG3jixAmz3ox9+/bxl7/8hWbNmhEUFETLli2tts+W1NRU1Gq12Xvj5+dHp06dzLY7fvw4f/vb32jRogXBwcHUq1eP/Px8h89T6siRI/To0QOt9vrjAF27dsXX15cjR46Y1jVt2pT69eublqOiotDr9WZfzVmy18Z9+/bRsGFD2rdvb3X/ffv20aFDByIiIip1TdZY++/h7bffpkuXLoSHhxMYGMiLL75oapuiKOzfv58BAwbYPObYsWM5deoU27ZtA4y9yD179qRNmzbVbq8QVSX3frn3O8KV9/6ysrKyOH/+PL179zZb36dPH44fP05xcTFdunShT58+xMTEcO+997J06VL+/PNP07aPPfYYu3fvplWrVkyYMIH//Oc/5UrjbhQSkp3E8onZtLQ0hg4dSkxMDGvXrmXv3r189tlngPFroopYPvihUqnMasyquo+9J7YtVeYayp6/9Dz22myPl5cXo0aN4oMPPgCMX7f16tWLm2++GYBLly7Rv39/fH19ef/999mzZw8pKSlW21ddgwcP5uzZsyxfvpydO3dy4MABQkJCnH6eUtY+T6j4PXV1G9Vq4+1CURTTOls3Tsv/Hj788EOeeuopHnroIb755hv279/PjBkzKtW2yMhI/vKXv7By5Ury8/P5+OOPK/01pBDOJvd+ufc7U1Xu/ZWl1Wr5/vvv2bJlC7fddhtr1qyhZcuWfPvttwB06dKF3377jXnz5qFWq5k4cSKxsbHk5uY6rQ2eQkKyi+zatYvi4mIWL15Mjx49iImJ4cyZM7XSllatWqHVavnf//5ntn7nzp0V7uesa2jTpg2HDh3i6tWrpnU///wzBQUFdvd9+OGH2bVrF4cOHWLdunWMHj3a9Nrhw4e5cOEC8+bNo0+fPtxyyy2VHpOyTZs2GAwGs/eioKDA7MGMP//8kxMnTjB79mz69+9PmzZtUKvVZnV1Go0GjUZDSUlJhedr27YtKSkpZnVzu3fvpqCgwO6DNBVxpI2dO3cmMzOTQ4cOWT1G586dOXjwoM2eq/DwcABOnz5tWmf5YKAt27dvp1u3bkyZMoXOnTvTsmVLs4dRVCoVt912G1u2bKnwOE888QTr16831X6OGDHCofMLUVPk3n+d3Puvc9W931J4eDg6nY7t27ebrf/hhx9o1aoVXl5egPGe2717d2bPns2OHTvo2rWr2TMfQUFB3HvvvSxbtoyUlBQOHjxo+kPkRiIh2UVatWqFwWBg0aJFnDx5kn//+9+89tprtdKW+vXr88gjjzBjxgy++eYbfvnlF6ZPn87Jkycr7GFw1jU8/PDDeHl5MXr0aA4dOsSOHTsYP368Qw9bxcbG0qZNG0aPHk1BQQH33Xef6bXmzZvj5eXFm2++SXp6Olu2bGH69OmValu7du0YMGAATzzxBNu3b+fIkSOMGTPG7CYeHh5OvXr1WLFiBcePH2fHjh08+OCDZl8ZqlQqmjZtyvfff09mZqbNr8amTp3K2bNneeyxxzhy5Ag//PADjzzyCAkJCXTp0qVSbS/LkTYOGjSIrl27cu+99/LVV19x8uRJfvzxR1atWgVgGtVi2LBhfP/995w8eZJvv/3WNBh/69atiYqKYs6cOfzyyy/88MMPPPvssw61LyYmhp9//pmNGzeSlpZGYmIiX331ldk2c+bMYf369UyfPp1Dhw5x7NgxkpKSzJ5Yj4+Pp0mTJsyYMYMHH3wQPz+/Kr9nQriC3Puvk3v/da6691vz3HPPsWDBAlatWsXx48dZtmwZSUlJzJo1C4Bt27bx6quvsnv3bn7//Xe2bNlCamqqqXTttdde49NPPyU1NZX09HRWrVqFl5cX0dHRTm2nJ5CQ7CJdunRh4cKFLFmyhDZt2rB06VIWLVpUa+1ZtGgR/fv357777uP222+nqKiIv/3tbxXWhjnrGoKCgvj666/JyMggNjaWMWPG8Nxzz1GvXj2H9h89ejQHDhzgL3/5C8HBwab1UVFRvP/++/z3v/+lTZs2zJo1q0rt+/DDD7nlllsYNGgQ/fr1IyYmhjvvvNP0upeXF5999hmHDx+mffv2PP7448ycObPcIPGLFy/mp59+omnTpjRq1MjquRo3bszmzZs5fvw4nTt35u677yY2NtY0hFpVOdJGjUbD5s2biY+P57HHHuOWW25hzJgxXLhwATB+Tj/++CPR0dGMGDGC1q1bM2XKFNPwaj4+Pqxdu5ZTp05x6623Mm3aNF5//XWH2jd58mRGjBjBgw8+aOqxnj17ttk2w4YN47///S8//PADXbp0oXv37nzyySemng8w/kJ67LHHKCoqklIL4Zbk3n+d3Puvc9W935onn3ySf/zjH7z44ou0bduWxYsXs2jRIh544AHA+MfT9u3bGTZsGC1btmTcuHE8+uijzJgxA4DAwEDmz59Pt27d6NixI5s2beKLL76gefPmTm+ru1MpZQsMxQ2lR48eNG/e3DQsjBCeYMqUKezZs6fcV8hCCMfIvV8Ix8iMezeI/fv3c+TIEbp160ZBQQHvvfce//vf/5g7d25tN00Ih1y6dInU1FTee+893nvvvdpujhAeQe79QlSdhOQbyJtvvsmxY8cAY33pxo0biYuLq+VWCeGYgQMHcvDgQR566CF5YE+ISpB7vxBVI+UWQgghhBBCWJAH94QQQgghhLAgIVkIIYQQQggLEpKFEEIIIYSw4JYP7pWd0ctROp2u0jPueIq6fG1Qt6+vLl8b1O3rq+q1RUVFuaA17q+y9+26/LMDdfv65No8V12+Plfcs6UnWQghhBBCCAsSkoUQQgghhLAgIVkIIYQQQggLblmTbElRFAoKCjAYDKhUKqvbnD17lsLCwhpuWc3whGtTFAW1Wo2vr6/Nz0gIIYSoKxzJJu7GE/JEVVV0bVXNKB4RkgsKCvDy8kKrtd1crVaLRqOpwVbVHE+5Nr1eT0FBAX5+frXdFCGEEMKlHMkm7sZT8kRV2Lu2qmQUjyi3MBgMHvVDeKPSarUYDIbaboYQQgjhcpJNPEtVMopHhGRP+RpDyGclhBDixiC/7zxPZT8zh/4EOnDgAKtWrcJgMBAfH8/w4cPNXk9NTeX999/n1KlTTJs2je7du5te++ijj/j5559RFIX27dvzyCOPeNwPVk5ODiNHjgTg3LlzaDQaQkNDAdi4cSPe3t52j/Hkk08yceJEoqOjbW6zevVqgoODueeee5zTcCGEEELUSZ6YTYYPH84rr7xCu3btqn2smmA3JBsMBpKSkpg9ezZhYWE899xzxMbG0rhxY9M2Op2OCRMmsGHDBrN9f/nlF3755RcSExMBeP7550lNTaVt27ZOvgzXCg0N5dtvvwVgwYIFBAQEMH78eLNtFEUxFYZbs2jRIrvnGTNmTLXbKoQQQoi6T7KJ69ktt0hLSyMyMpKIiAi0Wi09evRgz549ZtuEh4fTtGnTcj3EKpWKoqIi9Ho9xcXFlJSUEBIS4twrqEUnT56kb9++TJo0ibi4OM6ePcuzzz7L4MGDiYuLM/vhGz58OIcPH0av19O6dWteffVVEhISGDZsmGmGmNdff52VK1eatn/11VcZMmSI2Xuel5fH448/Tt++fXn88ccZPHgwhw8fLte2xMRE7rzzTvr168eMGTNQFAWAEydOMGLECBISEhg4cCB//PEHAG+++Sbx8fEkJCQwb948l75vQjjiwgUVBw541XYzhAtkZal59101p097RMWfEB6lomzSu3dvp2WTO+64o9LZpKx///vfxMfH069fP1577TXA+HDd5MmTTeuTkpIAeOedd+jbty8JCQlMnjzZ6e+ZLXZ7knNycggLCzMth4WFcfz4cYcO3qpVK9q2bcu4ceNQFIVBgwaZ9UCXSk5OJjk5GYB58+ah0+nMXj979qxDxfE1UUCvVqtRq9VotVq0Wi1paWksW7aMW2+9FTD2ltevXx+9Xs8999zDXXfdRUxMDCqVyrTP5cuX6dmzJ3PmzGHOnDmsW7eOKVOmmB1bpVKhUqnYvHkzmzZtYsmSJaxZs4bVq1cTERHBqlWrOHLkCAkJCabjlvXEE08wc+ZMFEVh/PjxbN++nfj4eCZNmsQzzzzDwIEDTUPXfPfdd2zbto1Nmzbh5+fHhQsXqvxe+vj4lPv87NFqtZXex1PU5WsD117foEFaDh1SU1hY5JLj21PXP7vadOqUlokTtXzyiRdRUXVzOCohalNaWhpLliyhY8eOADz33HPUr18fgLvvvpshQ4bQqlUrs30uX75M9+7dmTVrFi+88AJr1qxh0qRJ5Y6tKAobN25ky5YtLF68mI8//pj33nuPBg0asHLlSo4cOcKgQYMqbN/p06eZP38+33zzDUFBQYwaNYpvv/2WsLAwLly4wHfffQfApUuXAPjXv/7Frl278Pb2Nq2rCS5NlWfOnOHPP/9k+fLlALz88sscPXqU1q1bm22XkJBAQkKCadly7u3CwkLTsB5z5gSTmlq+d0mlUpl6SyurTZtiXnrpskPbGgwGDAYDer0evV5P06ZNadeuHXq9HjD+ZfTpp59SUlLCmTNnOHr0KC1atEBRFNM+vr6+9OnTB71eT7t27di1axd6vd7s2IqiMHDgQPR6PR07duT3339Hr9ezc+dOJk6ciF6vJyYmhpiYGNNxy9q2bRvLly+nsLCQnJwc2rdvT8eOHcnOziY+Ph69Xm8Kwj/88AMjR47Ey8sLvV5PUFBQueM5qrCwsNJzp8tc8p7Lldd36FAUUP5+UFOqem1RUVEuaE1dU7V7tRDuylY2qY7KZBNLTZs2NQVkgC+//NIsm/z666/lQrKvry/9+vUDoEOHDuzatcvqsQcPHgxA+/btTd9G7969m4kTJwLQtm1bYmJiKmzf/v376dmzp6mGevjw4ezatYsJEyZw4sQJnn/+eeLj4+nTpw9g7HSdPHkyAwcOtBvAncnud12hoaFkZ2eblrOzs00XZc/u3btp2bIlvr6++Pr6ctttt/Hrr79WvbVuyN/f3/Tv9PR03n33XdatW0dycjJxcXFWB7YuW0yv0WgoKSmxeuzS7Sraxpr8/Hxmz57Nu+++S3JyMiNHjqSgoMDh/YUQoiZUsV9DCGGHrWyybdu2WssmjggNDSU5OZmuXbuyevVqZsyYAcAnn3zCQw89xIEDBxgyZIjTz2uL3Z7kFi1akJmZSVZWFqGhoaSkpDBlyhSHDq7T6fjuu+8oKSlBURRSU1O58847q9VgW39VabXaKvd+OsvVq1cJDAwkKCiIs2fPsm3bNvr27evUc3Tp0oUNGzbQrVs3jh49avWPjvz8fNRqNaGhoVy9epWvv/6au+++m3r16hEWFsaWLVsYMGAABQUFKIrCHXfcwdtvv81dd91lKrco/VpGiNqmKOBhA+IIO0o/TwnJoq6oao9vTXCXbFLWbbfdxssvv0xOTg7BwcF8+eWXjB8/nuzsbHx8fBg2bBjNmzdn+vTplJSUkJmZSa9evejatStdunQhPz+fwMBAp16DNXZDskajYezYscydOxeDwUBcXBxNmjRh7dq1tGjRgtjYWNLS0khMTCQ3N5d9+/axbt06Fi5cSPfu3Tl8+DDPPPMMALfeeiuxsbEuv6ja0r59e1q2bEnv3r1p3LgxXbp0cfo5xo4dy9SpU+nbty8tW7akVatWBAcHm20TGhrKiBEjiIuLIzw8nNtuu8302tKlS5k5cybz58/Hy8uLlStX0r9/f9MfMFqtlv79+/Pss886ve1CVIWEZNvsDc9ZXFzMsmXLSE9PJygoiGnTphEeHo5er+edd97hxIkTqNVqxowZYxp1SK/Xk5SURGpqKiqVilGjRpkN6+kM8nkKUXPKZpMmTZrUWjYpKyoqiunTpzNixAgURaF///4kJCRw6NAhnn76aRRFQaVS8Y9//AO9Xs/EiRPJzc3FYDAwfvz4GgnIACqlqoW8LnT69Gmz5by8PLOvDqxxh55kVyl7bWXrmtPT0/nb3/7GTz/95Daz/jjyWVmqy3W7dfnawLXX16iRsbb31KnT1MaPt7vXJBsMBqZOnWo2POfUqVPNHo7evHkzp06dYty4cezYsYPdu3fz5JNPsmnTJtLT05kwYQKXLl3i1Vdf5bXXXkOtVrNu3ToMBgOjRo3CYDBw9erVCn/ZlbK8b1dk3z4v7rqrAR9+mE2/fnXzwb26/N++XJtRVX7f1TZXZSV3yCaOXJu1z6yie7Z7JCvhsNzcXEaOHGn6QXj99dfdJiAL4Qru92e8eyg7PCdgGiqybEjeu3cvI0aMAKB79+689957KIpCRkaGaTD/kJAQAgICSE9PJzo6mq1bt5qGiFKr1Q4F5MqScgsh6pa6mk08/wpuMCEhIWzatKm2myFEjTEYarsF7smR4TnLbqPRaPD39+fKlSs0a9aMvXv30rNnT7Kzs0lPT+f8+fM0bNgQgLVr15KamkpERARjx46lXr165c5vb+jOitSvb0zJQUHB6HR1MynX5SEE5dqMHB2e1t24os1hYWGm+0FtsndtlR2m1vM+XSFEnfb5535Mn349lElIdr64uDgyMjKYOXMmDRo0ICYmBrVaTUlJCdnZ2cTExPDwww/z1Vdf8eGHH1odvN/e0J0VuXTJC2jA5cuXOX9eyi08jVybUdnhaT3FjVKaaou1YWql3EII4TFeeimYoqKyT3apkHF1y3NkeM7SbcLCwigpKSEvL4+goCBUKpXZVLOzZ88mKiqKoKAgfHx86Nq1K2As0fj+++9ddg1SbiGEcGcyJ6gQotYZDFA6lLdlcCrbk1xScn27G13Z4Tn1ej0pKSnlRg/q3Lkz27ZtA2Dnzp20bdsWlUpFYWGhaez0gwcPotFoaNy4MSqVis6dO5OamgrA4cOHrc6SWl1SkyyE8ATSkyyEqHXPPRfCRx8FkJFxulxwKrs8bVo91q/3588/HR9Joa5yZHjOfv36sWzZMiZPnkxgYCDTpk0DjFO9zp071zSeetmpZx944AGWLVvG6tWrCQ4OZsKECU5vuwwBJ4TwBNKT7IC//vWvpt6YUitXrmTmzJkV7teyZUvAOD33448/bvPY//d//1fhcVasWEF+fr5p+aGHHqrRucuFcLWPPgoAjL3GimKeoMr2JK9f71nDLblap06dWLJkCUuXLuWee+4BYOTIkaYeZW9vb5566imWLl3Ka6+9ZhoJIzw8nCVLlrBo0SKef/55GjRoYDpmgwYNePHFF0lMTGTOnDl19gEtITxdbWeTlStXuiSbLFiwgOXLl1f7OM4gIdkBw4cP58svvzRb9+WXX5YbuN+WyMhIVq5cWeXzW/4gfvjhh4SEhFT5eEK4K2vPXFj7Sv7PPz3rYRlh7nq5hXQpC1FVtZ1N3n333TqfTSQkO2DIkCF89913FBUVAfDHH39w9uxZunXrRm5uLvfddx8DBw4kPj6ezZs3l9v/jz/+oF+/foBxyui///3v9OnTh0cffdRUFwgwc+ZMBg8eTFxcHImJiQAkJSVx5swZRowYwV//+lcAunXrRk5ODmDsZe7Xrx/9+vUz/bD/8ccf9OnTh+nTpxMXF8f9999v9oNcasuWLQwdOpQBAwYwcuRIzp07BxjHO3zyySeJj48nISGBjRs3ArB161YGDhxIQkIC9913n1PeWyEA1GpjEjYYyocma6NbdO0a4eomCRdSqYyft9QkC1F1tZ1Nzp4965JsUtbhw4cZOnQoCQkJPProo1y8eNF0/r59+5KQkMDf//53AFJSUujfvz/9+/dnwIABXL16tcrvbSmpSXZA/fr1ufXWW00h8csvv2TYsGGoVCp8fHxISkoiKCiInJwchg0bxoABA1DZKLr74IMP8PPz44cffiA1NZVBgwaZXpsxYwb169enpKSEkSNHkpqayqOPPsrKlSv57LPPyj25fvDgQdatW8dXX32FoigMHTqU22+/nZCQEE6ePMlbb73FG2+8wRNPPMHXX3/Nvffea7Z/165d2bBhAyqVik8++YS3336bf/7znyxevJigoCC+++47AC5evEh2djbTp09n/fr13HTTTVy4cMHJ77K4kbIAPVEAACAASURBVJX+56LXlw9Oxt5GSVNCCFFWVbKJLVXJJu+8845LsklZ06ZN4+WXX+b222/njTfeYOHChbz00ku89dZb/O9//8PHx8dU4vH222/z6quv0qVLF3Jzc/Hx8anmO+yBITl4zhy8rj15XZZKpaKqM2wXt2nD5ZdeqnCb0q81Sn8QFyxYAICiKMybN49du3ahUqk4c+YM586dIzw83Opxdu3axdixYwFo06YNrVu3Nr22YcMGPv74Y0pKSjh79izHjx+nTZs2Ntu0e/duBg0aZJpicfDgwezatYsBAwbQpEkT04xaHTp04I8//ii3f2ZmJn//+9/JysqiqKiIm266CYAff/yRt99+27RdvXr12LJlC927dzdtU79+/QrfLyEqQ602jlxRUmItJNdOm4TryWcr6gpb2aQ6XJFNbI0J7E7ZpNTly5e5dOkSt99+OwAjRozgiSeeAKB169ZMmjSJQYMGmQJ9165defHFF7n77rsZPHhwheMfO0rKLRw0cOBAfvrpJw4dOkR+fj4dOnQAYP369WRnZ/PNN9/w7bffotPpKCys/OD4v//+OytWrGDt2rUkJycTHx9v9nVHZZX9C0qj0VBSUlJum+eff55HHnmE7777jtdff71K7RbCGdTX7kQlJaoKh4ATdYMMASeEc9TFbOKIDz74gDFjxnDo0CHuvPNO9Ho9U6ZM4Y033qCgoIDhw4eTlpZW5XaW8rieZFt/Vbl6FpmAgAB69OjBU089ZVYUf+XKFXQ6HV5eXuzYsYOMjIwKj9OtWze++OILevXqxbFjxzh69KjpOH5+fgQHB3Pu3Dm2bt1q+uspICCAq1evlvtKo1u3bjz55JNMmjQJRVHYtGkTb775psPXdPnyZSIjIwH47LPPTOt79+7N6tWreenae33x4kU6d+7MrFmz+P33303lFtKbLJyl4nKLmm+PcC0ZAk7UNfZ6fF2lNrNJYGCgS7JJqeDgYEJCQti1axfdunXj3//+N927d8dgMHD69Gl69uxJ165d+e9//0tubi5nzpyhdevWtG7dmgMHDpCWlkZ0dHSlz1uWx4Xk2jR8+HAeffRR/vWvf5nW3XPPPTz88MPEx8fToUMHux/I6NGjeeqpp+jTpw8tW7Y0/dXXtm1b2rVrR+/evYmKiqJLly6mfR566CEeeOABIiIi+Pzzz03r27dvz4gRIxgyZAgA999/P+3atavw64uynn76aZ544glCQkLo2bOnab+pU6cya9Ys+vXrh1qt5qmnnuLOO+9k/vz5PPbYYxgMBnQ6HWvWrHHsjRPCDuODXCo+/DCAq1fNv+Cy1ZO8YoVx26efvuL6BgqXkD+AhKi+2somDzzwgEuySVmLFy9m5syZFBQUcNNNN7Fw4UJKSkqYPHkyV65cQVEUxo4dS0hICImJiezYsQO1Wk2rVq2Ii4ur9PksqZSqFvK60OnT5hMF5OXlmWpbbLnR5yN3F458VpZ0Ol25udTrirp8beC862vZMpK8POvVX3v2nCEqypiUGzUqX2N24sRpfH2r3YRyqnptzqiD80SW9+2KHD2qJSEhnBUrchg6tG5OoViX/9uXazOqyu+72uZJeaKyHLk2a59ZRfdsqUkWQtQ6dQV3Int/xuv18t29p5GaZCGEJ5CQLIRwucmT6/Hqq0E2X68oJPfuHUFenu0gfG2IUOFBpCZZCOEJJCQLIVxu/Xp/3nrLdkiuKDQVFKg4eNDL5utFRdVLXCHPPktUo0bl/qd+//1qHVfYJz3JQgh35hEh2Q3LpoUN8lmJqrDXs3junO1bVXFx9UKyf5kHTsrSzJlTreMK26TcQtQF8vvO81T2M/OIkKxWq+tsoXldotfrUVf0vbm44f38c/ke4ccfr8/FixX/3IwfH2rzNSm38DxSbiHqAskmnqUqGcUjhoDz9fWloKCAwsJCm9M9+/j41NnJMDzh2hRFQa1W4+uKYQZEnfHjjz506lRstu7rr/2qdczqlluImichWdQFjmQTd+MJeaKqKrq2qmYUjwjJKpUKP7+Kf5HKkDRCuD+N5vq/z51T4+3t+FdftjpsqltuIYmt9iiKvPfCczmSTdxNXc4Trrg2jwjJQoi6QaO5HopvvTWSwEDH55z+/HPrv4yk3MITGX8OpKRTCOHOpIBUCFFjyvYkA+Vm16vI4cPWR7iodk+yqHHSeS+E8AQSkoUQNeboUWPQrWjcY1u2brVeS1btmmTpzqw18tYLIdyZhGQhRI1Zt844HegrrwRXet/ffrNeHSblFp5HhoATQngCCclCiBqXleW8W0+1g5Z891/jJCQLITyBhGQhRI3z9XVeOlq/3r/cui++8GPu3CA2b3ZguB9JajVO/i4RQngCCclCiBrXvn2x/Y0q4O9/fVSMDRvKj3oxcWJ93n47iLFjbU9CYlJcvbaIqpO/T4QQ7kxCshCixvn4VC8d3XRTiXMaUlKCyuD4MHTCOaTcQgjhCWScZCFEjfvHP+pVa/+bb9Zz7Nj1IeG89u2jwV13cWHhQvJHjjStb8Uv6IaMQlVYiObPP1FfvgxAcUwMqNWo8vKq1Q5RNVJuIYTwBNKTLIRwe5Yz802ffsVsuf7Eicb/f+opSsp0MndmH94HDmDQ6UwBGUB94QLq7Gy0p04BoI+KoqBfPxe1XtgiPclCCHcmIVkI4fZmzLhstlyvnkWJRJlZSsqOwazBmJgvvvaa2eaFcXEU3Xrr9X0eeYSiTp2c1Vxhh/QkCyE8gYRkIYRLzJkTTKNGUTRqFGW2ftAgXaWP1bixeQ2y5egYSpmQPHTo9eOXhuRyU/2BWVJTJLXVKKlJFkJ4AgnJQgiXSEoKtLr+0CFvm/ts25Zl+vfTT1/vPR4ypIBlyy7wxRfn2Lo1i+BghVdeuWh6XVFdD8FpaddrlW2GZEUx786UkFyj5O0WQngCCclCCLfRpIkeALVaoVGj673HKhXcfXc+XboU06qVcZsBAwpNrxvU1p9BVmMsy3Cop1iSW41TFHnPhRDuy6HRLQ4cOMCqVaswGAzEx8czfPhws9dTU1N5//33OXXqFNOmTaN79+6m186fP8/y5cvJzs4G4LnnniM8PNyJlyCEqCu8rnUCJyQUUFhYcYBSqa5/V29QW/9739FyC1QqCck1yvjZSbmFEMKd2Q3JBoOBpKQkZs+eTVhYGM899xyxsbE0btzYtI1Op2PChAls2LCh3P7Lli3jnnvuoUOHDhQUFKCSX0RCCBs0GkhJOUt4eAkffxxQ4bZlc7Fi8Rzf1KlXWLIkSEKym5KaZCGEJ7BbbpGWlkZkZCQRERFotVp69OjBnj17zLYJDw+nadOm5QJwRkYGJSUldOjQAQBfX198fHyc2HwhRF3TtGkJfn5QVFRxaC2bey9km7925535QJlyCxs9zSYSkmuUvNVCCE9gtyc5JyeHsLAw03JYWBjHjx936OCnT58mICCAxMREsrKyaN++PQ888ABqi19YycnJJCcnAzBv3jx0uso//a7Vaqu0nyeoy9cGdfv66vK1gXOvr0MHg9mxBg1SMXeu8d/WzlG2F/JitkLjMq+1bWucrKS0JzmsQQOzfX18fVHp9ablgMBA0Ja/Hdblz84dSE+yEMKduXTGPYPBwNGjR5k/fz46nY5Fixaxbds2+lkM2p+QkEBCQoJp+fz585U+l06nq9J+nqAuXxvU7eury9cG9q4vysb68v71rxyGDSug7KFuvvn6Mayd48IFFdAQuN5jDMZSi7y8q0BDU0jOvnjx2pZGhQUFqIqK8Lu2nJuXh6qggGCLc1Tls4uKcvy6b1RSbiGE8AR2yy1CQ0NND90BZGdnExoa6tDBQ0NDadasGREREWg0Grp27Up6enrVWyuE8Aj//ref/Y3K8PVVKv0VfNlyCxXX05a/v4JWa1wuDc+f/8e8vlmvp/x3/lIDUGPkrRZCeAK7IblFixZkZmaSlZWFXq8nJSWF2NhYhw4eHR1NXl4el69NB3v48GGzB/6EEHXTlCn1K7W9l5f19U88cZWhQ/Otvla2aqtsSO7QoRhvb2jRotjUk/zsc2Fm+x487F3uwT2ZUKTmSU+yEMKd2S230Gg0jB07lrlz52IwGIiLi6NJkyasXbuWFi1aEBsbS1paGomJieTm5rJv3z7WrVvHwoULUavVPPTQQ7z00ksoisLNN99sVlYhhLhxtG1bzJEj1tOwt7f1tDRnzmWr68E8JJctt+jd2zh+8vbt5/jq9kL4HUowH91CrzcPxYpKhUTkmiPlFkIIT+BQTXKnTp3o1KmT2bqRI0ea/h0dHc3y5cut7tuhQwcSExOr0UQhhCexFXxsBWF7r9lSNiQnk0ArjlNiUQqmURvDs2VIPpmuoWuH67F4715vurQvRNQMCclCCE8gM+4JIZyqpMT6eh8f24moKiNDqtXXj5eLsea4xPi0n4n2WrmFwc6tbv0XFY/JLJxLKluEEJ5AQrIQwqkqE5JjYooB8PKqXk+yqdzC4uReaj0GVGCtmKJsuQUyTrIQQghzEpKFEE5VUmI9bHp7l19XOlSxlSGK7bL64J7BfOo9jaqkXKlFqY0br4/AoaDizFnr2wnnk3ILIYQnkJAshHCqMnN0mLHWk1waqMuWTjjKak+yRUjWqhSbIbmg6PoBFFTs3utrvoEkOJeRTnshhCeQkCyEcCpb5RbWHs4rzbSaKnTilg1apSFZZXFyrUpvsx5Zwbzc4upVi+0kJLucokhaFkK4LwnJQginslVuYa0n+bbbigAICqpeILXdk2y73EKxqFPOzZOQXHOM7628xUIIdyYhWQjhVLYf3Cu/bsGCi2zenEVYmKH8i5VgKyT7ehscCskKKkosezUlwbmM1CQLITxBFR6XEUII22zVJFsrt/Dzg3btbOxQCaYH9ywSuq+39XILy15kBRUZGRa3Q0lwLiM1yUIITyA9yUIIp7JVbuHr67rQaasmOTSk2GpPsgqlXE+yZXCWkOx68hYLIdyZhGQhhFPZKrcICaleSUVFTOUWFqnrpkbF1Au1320pIblmSbmFEMITSLmFEMKpbPUk169fAyHZMqEbDKi9HBvdwhND8oEDB1i1ahUGg4H4+HiGDx9u9npxcTHLli0jPT2doKAgpk2bRnh4OHq9nnfeeYcTJ06gVqsZM2YMbdu2Ndv39ddfJysriwULFji93RKShRCeQHqShRBOZasnuV6964nogQdyadeuqFrn8d24kU99x7CCcbRvdB4A9cWLBC1YgM+2bQQtWEDAJ5+gys+3ur+9kFxcXK3muZzBYCApKYlZs2axaNEiduzYQUZGhtk233//PQEBASxdupQhQ4bw8ccfA5CcnAzAggULmD17Nh988AGGMg897tq1C19fi3GjhRDiBiM9yUIIp7L14F5w8PUQNn/+pWqdQ3X5MqHjxjGqdMWf19bn5hK0cKHZturLl60eo2wotqxRNm7g3t2caWlpREZGEhERAUCPHj3Ys2cPjRs3Nm2zd+9eRowYAUD37t157733UBSFjIwM2rVrB0BISAgBAQGkp6cTHR1NQUEBX331FU888QSLFi1ySdulJ1kI4QmkJ1kI4TRnz6qZNaue1decGoisJHH9TTeRmZFBSWioQ4ewNsKF+Qr3TnA5OTmEhYWZlsPCwsjJybG5jUajwd/fnytXrtCsWTP27t1LSUkJWVlZpKenc/68sTd+zZo1DBs2DG9r84g7iYxuIYTwBNKTLIRwmn/8I4S9e8uHq+HD8+jcuXrlFXaVzlPt5VXupfnzL8Kz5us8PSRXR1xcHBkZGcycOZMGDRoQExODWq3mt99+4+zZs4wZM4asrKwKj5GcnGwq25g3bx46nc7h85dWcvj7B6DT+VX5OtyZVqut1HviSeTaPFddvj5XXJuEZCGE09iqR37rrYuuP/m17klFa7ytKV5eqK4VFt9zT16lQ7Jp7GU3FRoaSnZ2tmk5OzubUIte9NJtwsLCKCkpIS8vj6CgIFQqFWPGjDFtN3v2bKKiokhNTSU9PZ2JEydSUlLCpUuXeOGFF3jhhRfKnT8hIYGEhATTcmlPtCP0uw9xjClsP/Ym58+3d/yiPYhOp6vUe+JJ5No8V12+vqpeW1RUlM3XpNxCCFEtKSnedOsWTkaGhi1barFXsPQ7/Gs9yYq/v+kltZU7naf3JLdo0YLMzEyysrLQ6/WkpKQQGxtrtk3nzp3Ztm0bADt37qRt27aoVCoKCwspKCgA4ODBg2g0Gho3bsyAAQNYsWIFb731Fi+99BJRUVFWA3J1qYsKieFXvIrynH5sIYRwFulJFkJUyyuvBJORoeWddwLM1k+YcIXevQtrrB3KtSSslIZkPz+4ZHxA0DIkW45mUS4g4/49yRqNhrFjxzJ37lwMBgNxcXE0adKEtWvX0qJFC2JjY+nXrx/Lli1j8uTJBAYGMm3aNAAuXbrE3LlzUavVhIaGMmnSpJptfGmvv5v/ISKEuLFJSBZCVEtpzrEMokOHFtCxYw2Oo1bagNJyC7/rvdqWD4pZG83C03qSATp16kSnTp3M1o0cOdL0b29vb5566qly+4WHh7NkyZIKjx0eHu6SMZIBSt9qlfu/xUKIG5iUWwghHPLaa0E0ahSFwcacICtXBpot+/jUcAIq7Um+NiqDvXILS54Ykj2WjAEnhPAA0pMshHDI228bQ7DBYB46bQ3n5etbPgBt3pxFaKiLZt4rbYgDPcngQE2ycBmVWkKyEML9SUgWQjjEYCitIzUunzihocwwveVY60lu187GTCOVZDXOlta5ltYklxkKzl5ItlZ+4e41yR7t2l9ZKsV1U5ULIUR1SbmFEKJSDAY4eNCL3r0jWLLE9i3EWk+y01jpgVQsxklWrIyXbLZ9HahJ9lhSbiGE8AASkoUQlaIocPKkBoA9e2yXKJROGOGyRliyGN3C2qQiZoeQkFxrSsstFIO8x0II9yUhWQhRKZs3+3L1qvHWUdEDcc5+cE99/jyakyeNCxUE2LKTiVTEXkiWAOdC0pMshPAAUpMshKiUCROuz+pm66E9cGxEicqI6NIFVVERp//802q48jp82Hje0rGRL18GoLBXL6vHk57k2qO69rMhdd9CCHcmIVkIUWXODsIVURUVXV+wEmBV18amK90u/+67yf7wQ9NoF5bsjWYhAc6FpCdZCOEBJCQLIars00811K9fCyeuKFxde03x9q6wMNpyxj0Z3aLmqDQyuoUQwv1JTbIQolouXNCUW/f885dce1JbM5qUVclubsuQrJaQ7DrSkyyE8AASkoUQTjd+fK5rT1BRuCodL1lTPrybHUImE6k9EpKFEB5AQrIQgl9+0TJsmI7cXM8Iig610k5Psr3JRITrXJ9xr3bbIYQQFZGQLITglVeC+flnb1JSvGu7KY5xpAdSepLdlkxLLYTwBBKShRCe9+23Iw2tRE+ytWXhOsq1Hzh5cE8I4c4kJAtxg4mJieSZZ0LM1lmOd7xiRQCNGkWh1xuXt2/3qaHWOciBkKxUEJL9/MqXV9iZe0Q4k8f9VSaEuBFJSBbiBnP1qppPPw0wW3c9sxj/sWBBEAD5+cblNWv87B531qzLTmylHdUst+ifUMBddxWYlidMuMKLL9Vg+290EpKFEB5AQrIQApXKGFZycq6NX2uRYS5csH+rmDjxqkvaZlU1yy38/BSa3FRiWo6OLiE0TAJbjZGQLITwAA6F5AMHDjB16lQmT57MF198Ue711NRUZsyYwahRo9i5c2e51/Py8hg/fjxJSUnVb7EQwulKM8szz9QzWy61fbvtSTkAOnUyznIXEVFS4XZO44QH9yqcU1u4loRkIYQHsBuSDQYDSUlJzJo1i0WLFrFjxw4yMjLMttHpdEyYMIFevXpZPcbatWtp3bq1c1oshHC6snmx7OzPjlq7NhuAbduy2Lv3TNUaUVCAKvfa+MqFhajPnYP8fGP7LllMTuLIjHv2JhOxDMkSmmuOPLgnhPAAdkNyWloakZGRREREoNVq6dGjB3v27DHbJjw8nKZNm6Ky8ksmPT2dS5cu0bFjR+e1WgjhVGX/0716tcx0zQrs22f/iTZ/f2MwDQ5WaNiwasEnPC6Ohq1aAaC76y4ib72VyNhYKCqiYZs25htbCcmFPXuar6jkjHsSkmtQ6WcjHclCCDemtbdBTk4OYWFhpuWwsDCOHz/u0MENBgMffPABkydP5tChQza3S05OJjk5GYB58+ah0+kcOn5ZWq22Svt5grp8bVC3r8+dr+3YsQb06mVMKT4+128F3t5hqK+NY1u/fhh33WV/7GRnXKP2999Nx/I+fBgA9cWL6AIDy58rO9u0XHTiBKqMDFTt26MLCEB7bZiKkNBQFBvt8vH1hYDrDy8GBQaiBAeX285dPzuPJ+UWQggPYDckV8eWLVu47bbbzEK2NQkJCSQkJJiWz58/X+lz6XS6Ku3nCerytUHdvj73vLYoANLSrnDLLcYRHoqK6gPGESwyMi4COkDFmTM5QKTdIzrjGqPKHCuqzPrs8+dpaHEu7YULhJcu+/pCdLSxNCM/H51ejzdw8coVisu0q+wxCwsKKMnPJ+ja8pWrV1G0WkKdcF1RUVH2N7rRlZZbSFeyEMKN2Q3JoaGhZJfptcnOziY01PJXiXW//vorR48eZcuWLRQUFKDX6/H19eWBBx6oeouFEA5RFON4x3/7Wx7BwQq//qrl0CHrpRO2yi3efDPQytY1zFpvo8GBko5K1iQrUm5RY0yfqPQkCyHcmN2Q3KJFCzIzM8nKyiI0NJSUlBSmTJni0MHLbrdt2zZOnDghAVmIGrJtmw8vvxzCsWNeLF58kYSEBpSUWA+CZfNhfr7KtLxqlRuEZGuB2JFwZS/0SiiuPaZyC3lwTwjhvuyGZI1Gw9ixY5k7dy4Gg4G4uDiaNGnC2rVradGiBbGxsaSlpZGYmEhubi779u1j3bp1LFy4sCbaL4SwoXQikNKeYVsBGczzol7vXuFRZS0QO6EHslzPsYTmmnOtl9/qZyuEEG7CoZrkTp060alTJ7N1I0eONP07Ojqa5cuXV3iMvn370rdv38q3UAhRJaUdsCoVfPll+XGOJ06sT48eZwkNNZjlw+LiGmqgo0qsjL3sjHAlIbn2mHqSa7cZQghREZlxT4g6qjQkq9UwYUL55wj0ehVLlxrLKUpn3CtdX3a51rkqJIvaI6NbCCE8gIRkIeqo0vxR0fNrRUXXRhmoQk/yzJmXq9gyOyyDU1Vrku2RnuTaI6NbCCE8gIRkIeoog8EYRP74w/b0zKtXB7B1q0+5mmRH8qKXl4sCjl5vtqhyVUi2JCG55pS+146MUiKEELVEQrIQdVRp/ti/v+LJQN54I8giJDt2fK2LRllXWTbAWrmFU04kPcm1RsothBAeQEKyEHVQXp7K4bB75ox5T/Ply47dFrRaFwWcoiLzZSu9jU4ZFUFCcq0pHVlEMUhIFkK4L5fOuCeEqHnnz6vp2DGS6GjHiovPntWY5cMXXghxaD8v6/OS2KcoxuCrsV4GorIIySprRdISkj2b1CQLITyA9CQLUcdkZhrDZ1qa4ym2KvnQXk+y9//+R1SjRgS+9RZRjRqhzsoCoP7f/07UTTcRPGeOadsGZaalj7z1VrPjhMfFmS2HPvhghSFZ37QpAEpAQMUXYDnjnqvqR0R50pMshPAAEpKF8FDHjmnJy1Nx+LCWwsLr60+cqHzYq0pItteT7Pef/wAQ/Oqrxu2PHTOu37ABgMCkpOvHOnrU4fP6bt1aYUi+NH8+OUlJ6GNiKj6QxUUXxcZy8ZVXOP/55+QPGID+o48cbpOopNKeZKlJFkK4Mek6EcIDFRVBfHw4bdoUk5rqxYgReSxefBEwThJSllqtmEa6sKU6Pck6nY0H61zZM1tBuFICAigYNMj+MSwv2seHvEceAaDo9tvR6XRw/nx1WilsKe1JlpAshHBj0pMshAcqnWI6NdXYnbt7t+0RLGyU/lbK1q1Z5dZ5ecHly0Xs2XPW6j4uLV9wwtBh5aalFjWndPBuCclCCDcmPclCeCDLjFhcDD/+6E1ERPnwWFxsPwx++aVfha8HBpY/rlar4OMD3rbyeUWzmFSXKx7cEzXHNE6yhGQhhPuSkCyEB7IcOrikRMWoUboqH6+wsOLAaK032u7oFrVUbiE8gIxuIYTwAFJuIYQHsgzJjk4lbWn27EsObWetU9je6BaKM+o8bJA+YA8nM+4JITyAhGQhPJDlg3iOlFRY42hnr7WQbLcn2XInZ86cJ+UWHq3005MH94QQ7kzKLYTwQJZ509HZ9SxVZda8qCg9LVvqadnSTve1ZQKvane3NRKSPZsMASeE8ADSkyyEByofkisOfNYevAPHR74om2Xi4gr55JMcQkMrV26hqmqSt9egqpKQXHuufcugSLWFEMKNSUgWwgNVttzC29t6qKxOuYVd0pMsbDG999KTLIRwXxKShfBAle2UtVU/rNE4FlJCQw20aVO5kFuuJ1lCsihVWm4hD+4JIdyYhGQhPFBln4ErKLAeCO0+fFfGQw/lApXIlpbdz1JuIUpJT7IQwgNISBbCA91xR0Sltvfysh5GHO1Jhuu59PGU8QQuWWJzO/WffxLesychL71ktr7+00/TsGlTs3VBr79OVKNGDrehlO6++yq9T1mKnx9K2RBfmb8WRPXJZCJCCA8gIVmIG0CXLkVW11dmvo/SkNw7/SOC58+3uZ3/unVof/vN6mtlH94r7N6doDffLLdN/oABlISFOd4wB2Vt2UJRhw7kjRjB5VmzKIyPJ2/4cAp69yb/L39x+vlEBUpDsoxuIYRwYzIEnBA3AGuln1qt4tJJ8exRfHzKrcu7914uXgvOXgcO0GDIEKedT9+2Lee/+ca0XBIYyMW33nLa8UUlSEgWQngA6UkW4gZgORoGGHuRbY16YY2z84zVh7bK1AkrtZnghcsZUMkYcEIItya/hYS4Obt7KAAAIABJREFUAVjLoxqNgk5X/oUjRzJp27ahabkqE444xNrTh2XrhL29XXPeOuTAgQOsWrUKg8FAfHw8w4cPN3u9uLiYZcuWkZ6eTlBQENOmTSM8PBy9Xs8777zDiRMnUKvVjBkzhrZt21JYWMjChQs5e/YsarWazp0788ADD7ik7QoqmUxECOHWpCdZiBuAtSyi1UJ4ePmgWq+e+calQVpRnDwahJXkXvZhOulJrpjBYCApKYlZs2axaNEiduzYQUZGhtk233//PQEBASxdupQhQ4bw8ccfA5CcnAzAggULmD17Nh988AGGa5/HsGHDWLx4MfPnz+eXX35h//79Lmm/gkrKLYQQbk1CshA3AGudtlqt9Z5kS9OnXwbgjjsKXd8oGXHCYWlpaURGRhIREYFWq6VHjx7s2bPHbJu9e/fSt29fALp3787hw4dRFIWMjAzatWsHQEhICAEBAaSnp+Pj42Nar9Vqad68OdnZ2S5pv4RkIYS7k5AsxA2gtCa5V6/rQVertT8t9f335zJqVD4ALVvq+fPP005rk92aZAnJFcrJySGszCggYWFh5OTk2NxGo9Hg7+/PlStXaNasGXv37qWkpISsrCzS09M5f/682b65ubns27eP9u3bu6T9ikotwyQLIdyafJ8pxA2gNI+WHRfZkTGSqzQdtaPshGTpSXaduLg4MjIymDlzJg0aNCAmJgZ1mQ+7pKSEJUuWMHjwYCIirI/JnZycbCrbmDdvHjqdrlJtUFChVasqvZ+n0Gq1cm0eqC5fG9Tt63PFtUlIFuIGcD0kX1/35psX7e43YcJVF7UIu+UW0pNcsdDQULNSiOzsbEJDQ61uExYWRklJCXl5eQQFBaFSqRgzZoxpu9mzZxMVFWVaXrFiBZGRkQypYAi+hIQEEhISTMuWPdF224+KEr2+0vt5Cp1OJ9fmgerytUHdvr6qXlvZe58lKbcQ4gZgLSTffrv1CUbKataskvNfV4a1nmSpSXZYixYtyMzMJCsrC71eT0pKCrGxsWbbdO7cmW3btgGwc+dO2rZti0qlorCwkIKCAgAOHjyIRqOhcePGAKxZs4a8vDyzEO0SKhVSbyGEcGfSkyyEB/n2Wx8+/jig0vv5+hrDiK3pqWuDykpPsoxu4TiNRsPYsWOZO3cuBoOBuLg4mjRpwtq1a2nRogWxsbH069ePZcuWMXnyZAIDA5k2bRoAly5dYu7cuajVakJDQ5k0aRJg7I1ev349jRo1YsaMGQAMGjSI+Ph4p7ffgNp6XboQQrgJ+S0khAcZM6by0zV/8cV5brpJz4cfBhAYaODrr/3MXl+1KptHHnHiNNCOjlhgryZZQrJdnTp1olOnTmbrRo4cafq3t7c3Tz31VLn9wsPDWbJkSbn1YWFhrFu3zvkNtUJBLaNbCCHcmpRbCFGHdepURJcuRUREGHjmmStWR7MY0OcybzGBMCpXy1V/3Di0998P+fnUmzqVehMnErB8OcELFji0v+b338uvLBuSVU4el1m4FYNKjVpm3BNCuDEJyULUYZajU1jLnX4bNzKBf7GApyt1bL+NG1GvX0/A++/j//nn+H/xBSEvv2x124uJiWbLV8eNQwkKKrddYVyc+XaPP15hG3JHj65Um4X7MKg0Mi21EMKtSUgWwoM4MmxbRduXhuT27YvKrfTG/oN81qiKKt7vdEYGefffb7bu8j//Sf499wCQf9ddAOhvvpnCaxNfmLZ74QXTv/OubV9W7sMPV6HFwh0oqFFJSBZCuDEJyUJ4EHuTf1iy1ZPcuXOxaV3pw3IaqjiShV5f8eu2yiau1aOahnqrSn1qZd8Q4TaM5RYuHD1FCCGqyaEnYw4cOMCqVaswGAzEx8czfPhws9dTU1N5//33OXXqFNOmTaN79+4A/Pbbb6xcuZL8/HzUajX33HMPPXr0cP5VCHGDqOzkHpb5VKW6FkzL5tFrD8hpsRN2werDdvZ6ku0qfUDPXki28roidcsey6DSSE+yEMKt2Q3JBoOBpKQkZs+eTVhYGM899xyxsbGmMTXBOIDzhAkT2LBhg9m+3t7eTJo0iYYNG5KTk8PMmTPp2LEjAQGVH8JKCAFqtQLYD4a33VbE/v3eNnuSrYVkh3qSrYVkez3JtlxrjOJob7C1EC09yR5Lyi2EEO7Obr9UWloakZGRREREoNVq6dGjB3v27DHbJjw8nKZNm6Ky6NWJioqiYcOGgHHmp5CQEC5fvuzE5gtxY3E0EzZvbgyuxlBdXtm8WRpSHepJtjZLXnFx+XWV4WhvsITkOsWgkpAshHBvdnuSc3JyCAu7PoZqWFgYx48fr/SJ0tLS0Ov1RERElHstOTmZ5ORkAObNm1elubdlPnLPVZevz9nXptE4Fijr1/cBwMvL2+z8QUHGv4t9fHzR6Yy1wKr69Y1tRU+7dgaz7cu1PS+v3Ln87ARVa9ev0+nQ+BnHa/a99v8alarC98rH27vcuvo6HbjoZ6cu/1y6A0WlRi2TiQgh3FiNjNZ/4cIFli5dysSJE1FbKapMSEggISHBtFyVubdlPnLPVZevz9nXplJFAPZ7T1WqfCCQ4uIizp/PMa3PzfUH6pGfX8D585cA8MnNJQzo2yuPzWvPYGyucS57y7arrl6locW5Cq5epaICqtJjRFmsC87LIxAoKCggACjR662+V6X7FRUU4GfxWs7Fixj8/Ss4e9VV9bOLioqyv5GQmmQhhNuzW24RGhpKdna2aTk7O5vQ0FCHT5CXl8e8efO4//77adWqVdVaKYQAHH9wr3QaakvWKhtMU0FbK6Ww5IoH96rz8J2UW3gsRaVGhYRkIYT7svsrt0WLFmRmZpKVlYVeryclJYXY2FiHDq7X60lMTKR3796mES+EEFXnaEgODKw4JJuV95audCQkW9ummg/uWW+UFVKTXKcoyBBwQgj3ZrfcQqPRMHbsWObOnYvBYCAuLo4mTZqwdu1aWrRoQWxsLGlpaSQmJpKbm8u+fftYt24dCxcuJCUlhaNHj3LlyhW2bdsGwMSJE2nWrJmLL0uIusleSP7zz9MALF9uvQDCah69tuDIKBUqaz3JznpwryohubJj4gm3IeUWQgh351BNcqdOnejUqZPZupEjR5r+HR0dzfLly8vt17t3b3r37l3NJgpR+958M5DmzfUMG1ZQq+1wtDLBspPWcr1Z3vx/9s47zoky/+PvmZTthd1lgV2qIKAo1UNExQIeKupJs6CeimfBA7tSVA79WbAiil0UC6LcnQf2wiHCISqLoqgoHWQXWLb33ZT5/ZFMMkkmySSbrTzv14sXycwzzzwzyWY+853P8/2qwjdKu0XMsltEkydZiOQ2i8huIRAcQSgKiW++iW3gQGyDB7f0aAwjrjACgQEeeSSVG24w7sVvKsKKZKeTpMWLsTpqgUBd6dWj3o4kdyPrjz9i+f573w0aGkh94AFSHn4Y+dAhUh57LGCX1k2bIjoGD2rFPfegJFFx74hCkWRkIZIFgiOCuC++IH32bNLmzGnpoUSEEMkCQRtCrZgXjISVK0mbO5fT1z4ScnvdSDLQ8fzzfdonv/IKyc8/T8qiRaQ89hhJS5cG9GkymAGi+rLLAKicMQOAmksuQTGZqLnqKpzp6ZTPnRu6A2G3aFcooiy1QNDukcrLsWzZQubVV7veRzuHpYVolhRwAoEgNoTThFJVFQCJdaX660PZLfTaa4r/yNXVhsaoUpCf7/O+/NFHKX/0Uc97e9++HNi3D4CDv/wSvkNht2hXKMKTLBC0a+SCAjKnTMGira3RxnKjC5EsELQhGpMtTYvexD0t779/2PXiC83Clo4AiOwW7QpFkqOz2AgEglZP3Jdfknn55T7L6k4/HfOuXS00ougQYRiBoA1hNHAaTEwbjSQPG2Zj2DDfCXmNzofcWIRIblcosiTsFgJBO6XD3/7meV1xxx0U/ec/OLp18zztbCsIkSwQtCEizW7hjyqytXozZDRPu66xWSwaie44hd2izSLsFgJB+yRuzRrkOlcmqIYhQ6i++moahg9HSU6O2LbX0gi7hUDQhjCZjD2ejioFXLg+W1gk6xIr/4mg2VFkkQJOIGhvpM+YQeJ77wFQ9thj1EyZ4lmnmM3GUo22IkQYRiBoIzgcsHOnJaJtgqeA0ywMJZK1IrQ1epIFbRdJBiGSBYJ2g1Ra6hHIADUXXeTbQJbb3MQ9IZIFgjbCU0+lhFw/fnyN57UU5C87VMW9cEj19YbaNRlCJLcrFFnGJDzJAkGbJ+6rr8icOJGUZ58FoGbiRA789huY/cwKsqxbtbU1I0SyQNBG2LzZN4p8773lnteLF5ewcGGZ5334iXuaBkbtFkIkC2KIIgtPskDQHuhw7bXEffMNyc8/D0DF3LkoKYFBHUVvUkwrR4hkQbNRXi6xfHlCSw+jzeLvdkhM9P7QxMcrPokegjl1dYuJGI0k17VsSW5BO0OkgBMI2jzm7dt9JuNVT5mCMytLv7EapWlD0WQxcU/QbNx+ezqffJLAscfaOO64tlV1pzVgt/tK31CJHYJFkk880ZXG7aqrvD9qRh9/iUiyIKbIMjLCbiEQtFVS//EPkl95BYCSF1+kYcSI4AIZgvj9WjdCJAuajYMHXaHOhgaRkSAa/CPJWiEcbIKeP507O8nPL/BdaPSuXohkQQwRdguBoO0iHz7sEcgNAwdSd955BjZyR3baUCRZ2C0EzYb6dxEg4JxO4tasafciaO9eE/PmpUb8+/DWW4msWhWHzeZ74qx1FYxkPQBybTXWDRu8KyVIooqBZf/z2ca0dy8Jy5eT8M47JD/9NHJhoeHzbiopiWzgsaadfz+OOEQKOIGgzdJ58GDP6/rTTjO2URsUySKSLGg2VI3jbxOQn3qKzNmzKXn1VerGjm3+gYUhVtrsmmsy2LrVwpQpNfTta9xuMnNmOgDHH+9b8e7CN/7KzXxFMpWcv2I6yR99QOVNNwGuG5E3uYLxP63gYOEPOLOzAeg0cqRPH5atW6k744zGHFazUH/SSdROnEj8V1+19FAEsUKWkYVIFgjaHHJRked16dNPU2skigyei7+kKLSVkIeIJAuaDfXm0V8kS+5a7vLBg808ImPE6qa3qsoVCY6Li+7nwd+TnJ3/IwBTJpYSt+03ACT3BAoJhaF873odwiZh2r07oruAilmzOLBtGwd+/dVnue2YYwAoXbjQcF9GKcjPp/hf/6J24kQU92OIgz/8QEF+fsz3JWg+FOFJFgjaDPLhwyS98ALxH35I50GDPMtrJ06EuDhDfShtMJIsRHIEjBnTkXff1c/OkJ9vYuDATuzcadJdLwCn0yVw1AwLbYVYFQiqrXUdvynKr8jWrX6FRNyCUVKcgbOGJZAJcleiJcK8lc7UVJSkJJS0NN31Sny84b6iQQr2OELQ9pBNmHAIF41A0MqJ+/xzOg8eTNr//R8Z11/vWV5+772RddQGs1uIK00EbN1q4bbbOuiue//9eIqLTbz9dlIzj6rtoF4M21ol4Vj9PdfVuQ48VqJb0SZ68zupdruEyR2lU8KI5IgO0BKk4p/64UZ7BxAhIY9J0CZwWqxYsLWl66VAcMRh2rGDzKuvDlh+8Mcfqb7uusg6EyK5Zaiuljh40Ps4W8X/fbQoimsfoYjlZ19cLGOzhW5TUyNFta+6Onz6Li2Nrp9oaLsiOfSA6+qgoSFkEwCqqmR3+/AnIKLomqaxGmmtq/OK5JAfsMkU0c6UMCJZaSaR3FxiXNB0KCYzVhpavNq5QCAITvzq1QA4OnXi0DffANAwbJgr1VukwQpRTKRlWLIkiR49rPTr14Xc3Bzy8iwsXpxEv35d+OEHC7m5OeTm5lBVJXH4sOx5r/47eNC77NdfvXMZv/gijtzcHLp2zaFv3y4hx6B+9i+9lOxZ1r9/Z8aM6QjAY4+lBOwXIDc3hxkz0j3bvPlmIgMHdqZnT1ebK67IIC7OCsCNN6aTm5tDTY3E0Ud3YcKETHJzc1ixIsHTj9r3Bx/E89ZbiZ73Dz7oqn4zfHgnJk505TFct87Kccd14eabvfufNCnTs80PP1gYNKhTwJgHDOhMbm4OJ56YTW5uDlu3Bp//mZubw9y5qYD37+Kss7J9tn/pZa/gyctzfV7r11vJzc1hwYJkn/6GDvWO59Ah2Wc/d9yhbwEYMSLbs01BgXebd95J8PRz9dUdyM3N4fzzs+jRowunnurd5vnnvWP4/XezZ3/quR81Kpu//CUwN+TatVbi4qx8843Vc+4AzjwzO+j5Atizx0TXrq7+Tz01RFs9u4X7JFstisduEcpOoZhMjY4kK5IUfFZmUyFEcpvHabZipSHsTahAIGh+pIoK0u66i7T77gPg0MaNOLp1o/C//6XUXX46YjSe5IwrriDj8stjNNqmo12I5NNOq+Oqq7zPsP/3vzjWrnUZydXcvABlZTJ79gReXLdv94q8TZusntcffWS8OpyeNqislD0+0sWLg9sw3nsv0fP6wAHf8a1e7fV4rlzpaldR4bqobNzoOsYVKxIC+nn//QSWL/e+f/lll9ArLjZ5jlE9N1995TXdb9jgfb1+fRxFRYHnq6zMdbD797vO23ffWQPaaFm82LVvf5uBur2WL790He+HH7qOackS3/N26JB3PNrPDWDZMv1z/Mcf3nbbt3tF3rvvus7Pnj1mPv/ctb/vv7dit0vs2uXdZskS73n0Lw29cmU8+flmfvop8Bx8/rnrWD7+ODKf7ubN3r604whEFclKgEjudZSd1CR3iC6UCI7QbqGYdcajjUY3l0gWdos2j9PsslvEyn4kEAhig1ReTvapp5K0dCkADUOGeAIT9v79cXTrFlW/iia7Rfzq1cR/+WVsBtyEtIsrzXHH2TnrLG/4Xhsc27/fK6pcE8YCoxbayH+0195w2xnt18hTCP+LSrCJcGazd7nNJnHwoO8g1HNUXKwfldMby969gW2DaSz/7Y1EjNRjUx/BhsoEsXevOeg4g6GOtahIpqTE2IdSUuI9ZqufFlaU4MfkcKgTFQPX7dhh1h13YaEcMjLvs281kqz9ANydSoBFdqgDCd6JLEdmt/A/AQBms/AkCyJGsViF3UIgaGUkvPMOXY49FpM7zVv5vfdS9OGHselceJJbDpNJXyTPm+d9BB9cD3hVjLafSMSXLIduHG69ipHvjiq+VIJ5fP31yrBhnf32FVq06o1l5MhOYcej4n/+jJxPdZ+qbzdUZpm77nLZRML5t/XGMGhQZ3bsCOKvDYH2xgN8i9AF3hS4/tf7fE47LZs330wMWD5kSGcWLUoxNhh3x7Li0C/36TRmt4gkuwU6kWStD7nZxKuwW7R5FLNF2C0EglZE3Jdf0uH22wFwdOnCgZ9/pvqGG2K3gzaYAq7dFBPRXjNNJkX3MwgmkoNFkiMRyeEmo8Xymh6qPLGKogQKOn/CfU+NHn+wfvyXG4uSuw5GTZdmJKewfyW6UOiNIZKJhFarbx/19d6N6+okEhK8K4PlhVb5+efIRboWNbtFUJHsaIJIst7EPW0kWdgtBAZRLMJuIRC0OIpCypNPYsnLI37tWgAqb7vNVZgq2ETtaGmDIrndXGm0IvTNN5PYvTtQ/3/0UYKuHtB+XkauvcXFso+PFwJ1Rl1d8PGp6Hl5g3131q3ztvX3CeuN+ZNPEsIKc+2+9C5UeXmhvcbafn780RLgEY5UJP/0k8UTQVZFcny8d6NgGSSMZJbQjumDD3w9wqp/3QgWi+JzHA0NXpFcXS1RX+9KB6goXsEf7Dz+9JPrB2j/fhPffmvsXPugmbin6Ch9T4Q4hp5k3Yl72lzLzRXhFSK5zeMSyXZs9W3ngikQtCvq6rDm5ZHy5JMegQxQefvtsRfIoG+3aOV3ye0ykqwnkAHuvTeNGTMqA5ZrRY+2n2Ci7uKLM9m61cK+fQWe9tqIIsB99/lmWtCLVo4fH5gRIZjH9ZJLvG0vvTRTf2B+bNgQWnhpv6c2W6C+USfRhcPplDj3XFcWj/z8At3+9d77s+ydJJbgmnynnk+LxfshPPaYvg1BK1TDsW5dnGciocqCBQbtDbii89rvhdbqUVMjsWRJCgsWpBAfX+z529dOBtWyZYtr+Yknuiws2nMXju7d7VCmE0nWop7wUD9CEWa3CDpxT+91U9LW8ggKApDjXRdhW42ddnQpEghaN/n5xK1di/2oo8i68EJMJSU+q6svu6zJdu2ZuKddqCc+WhHt5pdJ79qtR2lpYATKN5Ic/tGzmgbM4fB+tuoj/8REV2d//OEf7TX2SNvIk2//PLvB9EJdXehom3ZfrpLH0eUuDD5xT/J7b7xPVddp/3b0smE4nZHZLUJniwhOd/byB908+1TRBjQbGiQqKyXPfmL1ROkYfqWGRPbSE4CTc7azfEMSyrHuMWhFslYQu1/HbdiA0qEDjtzcgL4VHbuF+eefcfTqhVRdjXnHDt8Nwkzc04toCwR6yPGu75JdiGSBoEmRKiqwbtxIwooVWN97D/8wm71bN0refBNncjLO7NApShs3kMBIsuRwRKk8mod288tk9EYkEk9yMNTP+b33ElAUiaIib/GPmhqZ0aM78ttv3kcVv/5qNjy+aIRVJKnqVDZssPpMmLHZMJxVwZ+aGm8/H3wQz/nnu7wmkUaStWgnA77/fjzp6U7d7R0OX2+vNhuaHocPR/6Yvi+/8zv9mcODvPXWrSRoTrd2Xw0N3pR98+enct55tWH7fvVVb9o6vbFlUMyvDHDtC4WxfMqnBedQ8uGLeFPAefMkayfhqYVF0ubNI23ePAr++CNwAJIUMHEve+xYlLg4JO2sRDdOTTlqR1YWpqIi6saMQbLZMO/Zg5Lqzolt9K41QupGjfJ5LChou8hx2kiyQCBoCqzffEPWxIlB15f/4x+RV86LFh1Pctrs2ZQ99ljoWfotiBDJRG63ULn9dm+J6kmTajyvtQIZXMUzevY0diGIZSEak0kJmnli0qQs7ruv3PPebpeC2hnCoc1FfcMNGZx/vss2ECiSjUcZtZPepk3LAODccwNFp8MB11yT4Xn/yy9mjjsu+LmuqIhcJHdnHwBn8CUPfzTH56ZEe1Nls3nzK9tskjs6H5p77/WKzjvuSA9Yn0S1z/tB/AiAdfNm4hKAcrjskkpYqBNJ9kcnDYjkcOgv9xPIhz/5BEWWcfTo4VlWuGEDWUVFlHfpgmS3UzV1Kva+fTmwZYvxRzsRUvLaa8jl5eEbClo9JrfdoqEygkkFAoHAOIpCujtbRTCqr7mmmQaDrkhO/Pe/aRg+nJpWWlik3Yhko9dkPeGitQUYyW6hF6kMVwLb6DyjWE76NJtDayZ/T/K+fdF9HfzzL+v1HynquMN9Hv43AeGEqb93vLH42i1810Wa/1VvbGrVPBUH7hsShwPJ5GrftYvNUP5JSS9XnsOhv9wP28CBAcuUxESUoUOhqAjFYsF+3HGu5RkZAW1jRnw8zvjIirMIWidSqmtugFJZDTThd0YgOJJwOsFup8NNN2H+/XcU96PPyptvJmXhQgCKly3DmZKC6Y8/mtcPrHqS/YRJ/EcftVqR3G6miBv9nPWEi6/dQuHhh1MYMqQTK1YE5rF19REoZj79NLTlIZwn+dprO4RcHw3anM96aPWU3S5RWBjd18G/SmBpqcR552WxZ49XdH/5ZZxPxDkcqvhdty5OsyywnX+5cK19YdMmC+PH+7qv/P3cscR/AmEkXmnQ/7yCimSnM6i/Kyh6YlhRIlfzAkEMkDq4n5yUVrTsQASCNo5UXk5Obi5JL75ITrdu5PTqRcIHH2DZtg3L1q3UXHQRlXfdRcGuXTTU11M/ahS2IUOou+CCZh2nJ4++X/qv+LVrkQ8fbtaxGOUIFMnhK+4tWpRCYWFs767Cje/jjxMCxtJYwkXX/bM0qGnXIsVfJH/8cQI//GDl6ae9WSSmTo0sUqQXEDVi1/j3v703NjNnpvPdd74+p8aIZElneoFWd/qL4ki1p97ThpAi2bNQI4xD7FTSW2cwkiwQxBo50xUYkMqFSPZBZy5ApKQ8+iiWTZtiMJj2h2XLFtJvvBHTnj0tPZSYYc3LAyDt/vt111f/9a+uF63E96s33yVz8mTS7r6bpBdfxPzbby0wKn3ajUg2brcIXBbMkxxLjNstYhfpDBdJ1loV7HYp6n1XVvoenJq2TWsf0OY7NoLe5xSpfUOvmEqs7RZaYezfd6T70rPxBBPJksMvo4U6cS+U4NVJKB3MkywQNDVyhsuPL/l5zE3795N+yy0kvfCCa4HDEfQHwfL99z6LLJs3Ix88SPyHH2L56aeYjVWqqqLzgAF0uOYask89FeuGDcEbqxeUykqs69dHtJ/kBQvo0rt34DnZuxfTzp10uPZaLN9/j1xSQsI//4lU6U1pKpeUkPDvfyMfPEjKwoV0vOACn4ubXFRE/MqVrmWt5G9eLizE8v33JPznPyQ//bRnuXXDBiybNiHV1iIXFSEfOoRcWIhUWhpR/6b9+wPOZeLSpSSuXEmKZn96SNXVoYV0bS0dTz+dxLffjmhMTYH1u+8Cltlzcii/917qTjsN2+DBLTAqHVS7hV8k2ZmejmX7dpKWLCHt/vvJHj0ayS81XUvRbjzJRsWt3tPoa6/1Rjkvv9xYDuJIMSKS58xJ4/XXk8I3jNE+d+zwtUPEyoqgZgnT5lk2UjlPi57ANCqSH344xXhp5whQCByTdpz+0fINGyK7a//vfwO9ttrotYQTp3pf63B4f3CcTu+HHWkk2ekUkWRBi2DKcaWashYfgoYG4j/9FKmmhvTZs5HcN3QJK1didYtdR4cOVM6aRfJzz1G6cCFx69aR+sQTnv7submY8/Oxd++OeZ9rsm3VtddSMW8e8Z98glRejqmkhJoJE3B27kzc2rVkXnopALa+fSn64AOUZNfTL8uPP2Lau5e6888HSSLx3XeRy8pI+PRTALImTaL4tddwduggG2fUAAAgAElEQVSAs0sXHDk5IMuYdu6k45//TOXdd2NevZqsL7+kYfBgKu+4A/tRR7kmvioKpn37sPzyC3Vjx3ouXlJJCamPP+46Jxs3Uj9mjPvA7HQaOdJ73vbvxzZwIElvvQVAw+DBlLz2GhlTp2L94Qefc5zw3nuYt22jato0Uh57jKS33qJ+6VLMv/1G0Ucf0XH0aOTqaqovvZTqa6/F3qcPlp9/xt6tm2duQdqsWSS9+Sb1J51E8TvvuCJSZWW+H2ZdHZLDgXzwIHJlJbbjjweTCet335E2cyYlS5aA04kSF4eSkkL8Rx9Re+GFpN1zDwkffeTpxrpxI7b+/Ul57jnAVeHTmZyMXFvrEVYHfvsNJSUFuaAAuaIC+1FHgdNJ2ty51EyejG3YMDInT8a0bx/mggLsOTkUrViBMyeHrHHjsP7omvysRtpNe/cS/9lnOLp1I2X+fKQ5c7BkZtLxL38BoGDfPjCZsGzZglxcTP3ppwPQedAg5Opq0u+8k5qLL3YJ+fJy7MccE/J73xRYv/3W533B3r2uF2ZzbMtKNxb1muUXSS57/HEy/vY336ZVVTiacn6LQY44kWwk40BTEC6qC8RUIEP4egtff+3Nebtsmb7/Ohqs1sBjbU6RHAuBfOqp9T5+6GA0tb7URpJlnF67hTbXndNbcU9XCLvRFcOuRNMxG69AYJT03q6AxBkr51CVsZ3k114LaGPVRINNpaWkz5wJQMcLLwxoa87Pd/3vFsgAyS+/TMLKlZgKC73LnnySQz/+6BHIAJZt2+jSr19An45586i98EKSX3wxYF3m1Vf7vC9ZvJgMd6aAtHvv9R7D5s1kuiclVV92GYnLl/v8LR5euZKM66/3+YHLvPJKABqGDsXqFy23/vQTFs3jaOvmzXQeMiRgfAAdbroJcP0umApcWYfi3NHtTiNGeNolLVtG0rJlPttWTZ2Ks0sXkt5807Xdhg3k9OhBwwknYM3LI/muu6iaNo0O06Z5bh5UGoYOxda3L0nvvOPal0bkO+Pjkevq6KCTdSF+9WriV6/2vJdsNkx+0eMu/ftTMWcOqQ895OovKYnaCRNIWrqUpKVLUSwWn/NrLiig8/Dh1EyY4BHIAJYdO8jRyR3P1Kl06NrVu/2OHTizssgcPx65tpYDv/yCkpiIXO3NPJTTvbvndUF+PqZdu0h+6SUqb7kFZ2YmcV9/jW3AAJxZgQXEokUqLaXjn/8MFgtmVRQDh9avb7LsQo0mSCS5/tRTqbj9dmonTSL+889J+8c/Wk0lvlZ6JiPHiAiFVnPem4VI/M1NffMQqd3i0KHAu55g6eyagvh4hZ497T6TD/WIpNpfNGhFsgmHT3YLDwY9ycFSwIlIcttl8+bNvPbaazidTkaPHs2FfuLRZrOxaNEidu3aRUpKCrfccgvZ2dnY7XZeeukldu7ciSzLXHXVVQwY4MrHvWvXLp599lkaGhoYMmQIV199NVITFIlJSZWoJpEkagIEcvHrr3uEYvEbb5CpeirDoBVI9SeeSNy33/oIZAC5tpYufft63lf+/e+kPPusbn+mQ4c8AvnQ+vUkrFhB7aRJdDrxxIC2GQZSaSUtXRqwTI1Y6uEvkFWkhgaK/vlPsiZP9llee+65JHz8Mba+fbFs2+ZZnqxaVyIg+dVX9cfk9r+mPvooqY8+6rNOiY9HqqvD+v33nrH7i1ZZI5DsOTmYCwIrjdqOOQbL1q1Bx6YKZAC5utoj5CG45SzxvfeC9uePef9+z+vsM8/0WddlwADqTz0VgNInnggQ+4lLlhC3bh0Jn35K4ltvefLVAxTs2uXyBdfXI1dX44wmUupwYN66FfP+/T7nrvj115FLSnD07Bl5n81FkEiyEh9P1W23AeDMdD/Nj1CsyQcPIu3dC5o0pbHAkFN28+bN3HzzzcyYMYMVK1YErP/111+ZOXMml1xyCd98843PujVr1nDTTTdx0003sWbNmpgMWg+jkeSmFjXBMJKf12hVPqOEE8na614sdZJeX7GYLxDL9HjhiItTDFlkYu1x9sdfJKt2C20WC0mb6SKKiXsiu0XbxOl0snjxYubMmcOCBQtYv349+zUXd4DVq1eTlJTEM888w7hx41jqFmmrVq0C4IknnuCee+7hjTfewOn+A3v55Ze5/vrrefrppzl48CCbN29ukvFLEvTNLuHD/jdRP3w4hatWUbBvHwX5+dSPGUPxW29R9tBD1I8ezaGvv6b0qadoGDaMgj17PCIFoOL22znw++8U5Odz8Oefqf3znyl+6y2Kly+n4YQTqJk4kcI1ayh7+GEq//53ai66yLNt5U03UTlnDodXrqTGT3BqUeLjcfTsSdUtt+Do2pXCVas4tG4dhz/+GFufPlTeeCPOpMAngfacHA5/8gmV06fj6NQJe8+elD3wAIe+/ppDGzbQMGhQwDaFa9b4FOOpHTeOwlWrsB19NOWaiVkNJ51E4WefUarx1pbPm0f9ySdTtnAhlW7RoaVo+XLK587l8AcfAFB1zTUU5Odz6LvvKH7tNRoGDqTq+usDtit57jnKHn7YZW3QOz9mMyUvvsiBnTtdkUw3h/73Pw7s2UPh559zYOtWil9/ncrp0ynYs4eDW7ZQuHEjFXffjSM7m8MffkjpggU4srJcxSXc46uaOpX6E0/E3qsXBzdupGz+fE//FXPmeF7Xue0p9SNGcOibbyheupSyRx+ldtw4z/qCffuouPNOCjXRaoCif/874Ji0+wGoHTvW8zpu3TpXn+ecQ9nDD/u0S7/7bk9kXfK7COccdRSpc+eSeeWVdD7+eORDhzy/v3Fr15Jx5ZVen7nTqXvRS1y2jOyxY31uyipuv536MWOo1Xy3WyOeJ55+kWStgFO0NkIjOJ3EffUVaffcg3nMGCR/K1AjCRtJVn+I77nnHjIzM5k9ezYnnHACXTWPI7Kysrjxxhv5wP2Hp1JVVcW//vUv5ru/bLNmzeKEE04gOTmZWGP06UJTi5pgGInqms26c6uadJ8qsYwk692IxOIGIJaZP8JhNiuGxqzeEBi1Z0RKULuFfwo4A3YL3S+XoohIchtlx44ddO7cmU6dOgEwcuRINm7c6PPbnJeXx2S3+BsxYgSvvvoqiqKwf/9+jnPntU5LSyMpKYldu3aRmZlJbW0tfd2R1lGjRrFx40aGBHmc31hye8AFeU/x6qslpFcqVHwpsXGjldpaiXPPHct35VZ6rLRjNvdj2/4BdJhwJckrFSrO/A/9Jh7Ant2F3btN7HrUzFFH2encOZ6G8cvIsDip/VLi2Oc+YO7cNE7/pp6jeg8gc7iT77618EPR41wwNZHkZIX4LQpltSMpPPVU9nRbTFbFLmzdetI/PZ/fSzrTqWwbh20dyH8glbPOqqOiQuKnn4ZTVwfHH28j77QfyEhyMvSV+0l/fzm7ClMZPsaKPb0n8tDu7N5tIi9+JA0XP8TJJ9dTUiLTsFFi0CAbiS9/SuKceciSk2/iTqPH4CTKigdQvGAfRx1lZ1d+EklJCqm1TlJfWcfu3WZS3vkbFQfq+OmJVKzWEZwxsAcjO/bgw4tewLK3F6lz36O2VuJr80iU2+7BsnUrD35yMpuvfpCl343lwgtH8d13VhKfL8IaJ/Ht/VaSk5M55ZRe1M0+D6dTYtvOSfQc1YnUvVupzOxGp569KTxsYtcV09h2/8dc/NSfqD5UyJmf/oOKhni2z3+V9evjGPCljdTUo9k5LY++bCPF2Yekgwr5dYP5/l0r3bufx4ArxlL6m0xhYTIWi0JVz9vovPhmOmU7qU87gcIXLyct3kn8ugPEJ0BxsczhAwrbtsocu1Mie/jVDJxvojYujV1DLqBXYifkLb/yw+R76H13KV/9lkv6bid79vXjz3+uw3L2FdTNhcQEB6lI7JpyG/HxCqannyH5n8spnzcPe//+VNx5J3JJCXEXXIBtyRKqJ02m5tJLSf2//6Nh6FDq/vIXqteuJfnll1GSk7F37YqSlkbNFVdgGzQIe/fudHH/TYFLlFvz8pDLyqi64QZPND958WJPm6wJEzDv2UPt+eeT4NZPXfr3p+7004lfs4b6U0+l9rzzqJkyBWSZ5KeeItV9AwFQf9JJmA4epPbii5vk7zPmqJEn/+wW2oidSedpaQgS33mH9DvvBMB+770o6YFFuRpDWGlp5Ic4213r2/+R3ObNmxk4cKBHFA8cOJDNmzdzyimnxOwAVIxHkmO+a0MYEXixjnKXloY+Kfv3ez9+PXtDtOj5m3/5xaLTMjKaM5Isy8YmW6qf2XHH2ZpEJGsn7mkjyT4iWZvpQqSAO2IoKSkhM9M70TgzM5Pt27cHbWMymUhMTKSyspKePXuSl5fHySefTHFxMbt27aKoqAhJkgL6LGnCWebnnlvHxo1xXH114ITpxYvDBVOMT7IOzGPfgeWrdZsCanRXrYbp9e4+/3y4MU1z/fdf/bVPP603X0JjhfgwTPc6PEIqsAeexfUvgJEs5gCFr2WjIPP446m6/WjmQAJjYBXA8a63Pq6KS1l2M0Af4AvXovP8e+sIDIPnjR9HZNyBxaK4swu5fNe8C9DVp9Xs2aH6mA5MJ/F8J506Odm9+1Hi4xXqFkvABfAf6NXLzu7dL7ua3whwCXfddS7DhjWwY4eZ7I+dnHxyPSnHD0KW4eB337n84g4HDcOH+wi2mvHjydZEowHM7uwZCX4Bxnj3U/e4deuIW7eO9JkzPfYhLcX/+lfo09TaCBZJ1mJQJMf9979IVVUegVx77rmY7roLKmKbUjKsSDbyQ2x024yMDN0f3FWrVnke/82fP5+sKMzthYXGQskNDY0Xa9EgSc1Y1aaF+fbbQLEYi9R2JlPzfXZJSXGYzeHHrKaAy8wMXUwmWvztFqpojq+vR3L/mKQmJWFypxSx1LjKo8fr/Ail6eSmNBtMARfsb9JsNkf199oWaM/HdsYZZ7B//35mzZpFx44d6devH7LRPJVuGvu7bTabmTkzgV27XBfD+no4+WSFnTslfvpJoqoKfvhBYtgwBbMZhgxR2LdP4uKLnezdC7//LvH77xIpKXD88Qo9eyps3iyxapVMWRmMG+ckPR1275Y47jgFSYLychg8WMFuh2+/lejfX6GhQaKoyLWurk6ipMR1nR02TOHrryXGjlUYNcrJzp0SGzdKbNok06+fQrduCmee6eTdd2V++kkmN1fh7LOd/P67RI8eCnl5Jnr2dG13wglO0tLgs89k+vZVyMlRSE+HbdskDhyAjRtljj1WYfBgBZNJ4d13TXTurNC1q8Lu3RJffy0zebKDmhqJ3FzX9vn5EocPS+zbB+eeqzBokJMtWySqq13n5cMPZRISFK6/3onN1pHjj3dSV+ekutq1v7o62LpVorgYpkxxYrdDYaFEdTV8+aVM794KxxyjUFQExx2nYDLB++/LHDggcdZZCoqi0LevwoEDEqWl8OuvruOOj4fOnV2fmc0GPXu6gkRduyq8/bbMxo2u71mPHgqjRzvp1k3hvvvMDB/uZNIkJ/v2SSQnw44drkBFVZXE7t0wcKDrs1q/XiIhAUaPdiLLkJYGzz0nk5AAJSUSPXsqZGUp5OXJnHOOk08+8X6vhw938t13MomJCt26QWUl5ORAZaWJpCSF6mrf3/zduwN1xaOP6t9k9Oih0L17Z447bihDhij8tbfTd/L86adjf+opTI8+iv2FF5D27kX66itITsa0ZAkAzgkTkN97D/szz2B65BEkjX3KXyDbX3opqt+nlvxdk9w3Dcl+fnPteNQ2HVJTUXTGKf36K0pCAlbNPAXnhAmYli1zHZvVGrBNY2gVE/fGjBnDGDXdDVBUVBRFL1lA+JNTWemgqQ47OdnJv/9dxNix2QHr7Pam2++RQl2dHSOfsR4zZlSyZYuFNWuMlTS22+tQFCta275eMREVRakG9H88tVx1VTVLloTPYnLCCQ3k5VkD7Bbqe/njjz3LLRMnese4cycAJh2PnUUzm9/T56+/wq+/hhyL/aijgv5NZmVlRfn32vqJ9thycnKaYDSBZGRkUFxc7HlfXFxMht9EILVNZmYmDoeDmpoaUlJSkCSJq666ytPunnvuIScnh6SkpLB9qjT2dzsrK4vS0iL8rJ+NYtIkeOAB420jYfhw0PkT4uST9dvPnh34/dHbXg8dW7AhNEkkQqL56CNi7lzX/9H+bQSzzF53XXTjUdGxX/ugKK6Hb0aeOKvHVlfnSmf6v//F0amTg7o6ia1bzaSnK9TVSXz8cTxFRTLffhuHyaSwd6/E3r0Sbruy55geeaSMiRNrSUhQYPJk1z+AYcNgwgTM27aR7RbJxddeS6LVSsWf/4x06ql0mDaNhqFDSXn2WRoGDaL4X/8ibeZMKm+/3TVBL4rPoCV/s+OqqsgETH4RcO144qqryQTKioux+Y1Tqqyki471q3TyZOqLiprkNzusajPyQxxq2181F+CSkhKOPfZYQ9tGilG7RU1N09VPcTggNVVfSDWnn7a90phzKMuRFYqR5fAp9LQkJMTWC6L6of0jySYim/Fb/de/Yu/RA6m2FmdGhittkaLgzMjANmAAFndeVdvQocilpSiyTPznn+Po0QOpshLJZqNGI8IFrYfevXtz4MABCgsLycjI4Ouvv+Ymd8ovlWHDhrFmzRr69u3LN998w4ABA5Akifr6ehRFIT4+np9++gmTyeSx0CUkJLBt2zaOPvpo1q5dy9lnn90ShycQxAxJirxQWLw7njJqlPcJ3KBB3qduF15Y69O+pETipZeS+e47K1u2WDxaY+bMdObOTePRR8u44IJa/AOdSrw3cGMbOJByt+9FSU722CkqZ892CQyzmbJnnonsQFoRipGLahC7hXn7dpKf9/XvHF6xAkfXrji7dInVEAMIK5KN/BAHY/DgwSxbtoyqqioAfvzxR6ZMmdK4EQfBuEhuuol7iiIZTkUniJzGpO8zmYynCVTbRzLZMDExsK0sK1HbTNQn340VyTWXXopt4MCg6/XWNTTBnAFB7DGZTEydOpUHH3wQp9PJGWecQbdu3Xj33Xfp3bs3J5xwAmeeeSaLFi1ixowZJCcnc8sttwBQXl7Ogw8+iCzLZGRkMH36dE+/f/vb33juuedoaGhg8ODBTTZpTyBoT2RkKMya5a2AWFYm8cEHCTzzTDL5+WZuvrkDN9/cgZdeKmHcOK8dTiuSgyJJrTf3cSRoLF3Fb73lyR/ug1pcRzsJyeEgc/x4T87sirvvxpGTg+1Pf2rS4YIBkWzkh3jHjh08/vjjVFdXs2nTJpYvX86TTz5JcnIyEydOZLbbPT9p0qQmyWwBxr8/TZkCLtTjHEVpmawaLcUtt1Ty1FOxrXrXmM9Olo2ldFMxmSJrr5cH2mSKfrKh+n0OZrcwitIeflgFQRk6dChDhw71WXaxZqa71WrlNp1n0dnZ2SxcuFC3z969e/OE7ywugUAQIenpCldcUcMVV9RQWChz332pfPZZPNddl8H559eycGEpcXGgJDTNfJbWiLYAi6KTMhG8KeDUqJha8VFL1bRpkT3qbQSGrqDhfoj79OnDC0GSlZ955pmc6ZeMuymI9FFKUxBKJB840AoG2IzoRVYby++/Rz9xzxUZNt5eL7uFXllqFf1IcmA7o5YRs9nV0D+7RaSR5IBnewKBQCBoVrKznTz7bBl795p49NEUVqxIZNMmC8uXF9Orq7F5Mu2BulGjqL78cqqvvhrJ7TAIwC2i0u65h5pLLvERyKVPPul60tlMAhkMFhNpC7R2kdzWSU+PLIKZmNiM+doMYDZHJpJNpkg9yYHqV5Kiv1FQv0eNtVuISLJAIBC0Dnr0cLBoURm33lpJQYGZU07pxG87j5xIMgkJlD/yCPb+/ZGDpZZ0X/wsv/1G2rx5ADgTEihcvZraiy/GoVdKvAlpNyI5Gi0waFBskyY7nVLMq+a1Fh56KLIqNnqiMVLUaGosMJuVKDzJxvvXO95Itu/d2zcNm3rsjbZbWFom5aFAIBAIApEkuOOOSmbMcPmXL700k63T51P4xRctPLLmpcGdFqbGL82M4nfhLHnxRQ7u2IG9X79mG5uWdiOSI0zxCXhz3MaSpo4kt5QIj/QmJBYiOVwfAwYYL4JhsSgRfTYuT7LxY9Aba2O+C7GKJCNEskAgELQ6Zs2q5I03iqmokDh20Uz++fuwlh5Ss6IkJVGQn0+Z/9wIzYXTduyx1J0XUKmmWWk3Ijkaiotjf/hNLZJbSvNkZkZqt2i8SA5X4+Ltt4tDN9BgNkdmn4g0kpyUpB9JNmq5OOcc3+IfFktsUsAJu4VAIBC0TkaPrueLLw7Tt6+Nhx9OMVLXqf3jFlHOpCQOf/ZZCw/mCBfJ0USfw/fZtJHelkox16VLZOLMXyRbrZGPu64u9AeUleUr3Pv1C/4LE3kkOfD7EaqYiN7xKQpcdJGxmwv/sanvtfuMxm4hJu4JBAJB6+WooxzMmVPhThOXHn6Ddo7ivvgpVmvTiLQIafkRtCBNIWibOnDX2EhypBPwVDp1apxIVunTx/it8vDhgWWUQxEqUmw2R3aDIctKRJHnuMBK3AD06uX7Plh2i/Jy2SfqLCbuCQQCwZHBmDH1XHttFStXJvLxx0dOtgtd1ItfK7EKHuEiOfZ9ms1w0kmRibvI+o9e2C9dWswTT0Q2AU/FSL5zLf4iWVHgq68Kef/90CUj16495Hn9+uslPPJIdOP1x2Lx5j2eObOCs86qC9k+EruFyaQEjSTfeaeDN94oZv36Q2zadDBoH0VFMps3H+KCC1xVnPQm7glPskAgELQ/JAlmzqyke3c706d34I8/2mmaLCOokeRWcu06okVyU/mHjz02dLS0Vy971H035nszcKBNt+hFOHr0iHy8/mLe6YQ+feykpYXe/1FHeUVgaqrC8cfHxqSlTQGXmuqkT5/QxxRJxT2LJbidJDnZ5Tvr2dNB586ho/hZWU66dXONS6/iXlR2i/aak1AgEAjaEQkJCi+8UEp9vcS113ZoVIXZtoyndLUQyU1LLvtRkFCQSCMwGvkK17DosLdE9kB+REFiHafQh+3YMXE02zzrL+dN/qAr3dgHuCZkHcsv2DDTk90+fes9ps8hnwYsDOF7JkyoYQ4P8h1/YibzPeMcz3sB293CAnbRi1TKAVdE9CPOZQMjqMeKgsQ+urGPblSRRCrlDOdbakigNzuoIsnT/3HHd2HKZVn8QVcasNCVPwCXCP6KUTzA3brn0r9q3Jln6kdhU6hgDz1QkOi53lVz/v+4hy0ch8mpL3bP5hOm4SpE8zw3kvLM0z7rc3Md/J1FbONo3e21qMIynlpK6MBCbmIf3RjBBiwWhb99cyP55JBcsp8Rv79FPjlIbtE5l/vYwAie5FY+4WxDFfeqSURBIkcqwGKBPfTgGl7xrNezVmiX9WE7Nsw8ya0s/m8/ss45h0XPprKfXE480ZWeUCuK46njPuaFPQ8CgUAgaHsMGmTjqadK2bLFyuzZaS09nBZBLUfdWqyC7VYkj+Mjz+uhfB+w/hpeZVz1Pz3vb3ALtVNYzxTexoSTy1jqWX8TT9OVfHqzE4BOnZxczWuYcTCRf/v0rSeuzuZTLNiZziJuvbWKB7mHP5HHBbzvaTOYzQHbPcQcerGHLhwAXBHRc/mEEXyLFZfw7MZ+urGfJGoYwg/cyWMkUMcMniGJmoA+u5KPBTvn8jETJ9awZk0ho1jH3TwUOHACRfJrr+knAc8lnx7um4jc+Xdz5ZXV3MODHMcvJCvemvZxcS6l+MorJTzAPT59pD7yiM/7rCwni5jB0ezQ3aeWjAzXQLuzjw6UcRPP0I39nMx6zGYYtf0NcjhAWsleLl1zMzkcwIpLjN7HPEbwLbfyFGfzmY/d4pabK3T3l4jLGnGWtArJ6aAH+3iFaz3rw0UCpvA2ZhzcylNk1/6B9aefAMilgBEjXOPSTtxLxXcctqOPpuLuu6k/6SQaBg+mZtIkai66yLO+7OGHw50ygUAgELQiJk2qpU8fG0uXJrF2bZDJLu2ZBnf9ilYSSW4dUr0JsOE9waHKCRvF7j5VFrcw7dDBie2gax9mfB/d64lkdTxm7D6RZu22etkTVA+qui6cJ9mM3XO8Ro47Lk4JmwDB4fDtJ9gNnnpuVJKTvepae2wJCQr19VLMM3VkZQVXpdrz5nQoOGQLFmcDZuzoOci1FffUv9Vg51OS0c1X53/e/NF+R4Phb7fQUvzPf+Ls2JGqG2/0WZ64fDkAtRdcELZ/gUAgELQeJAleeaWU00/P5umnkznllPrWkOSh2XGmt45MH+321NuD6P9osztoRXJqqhNJAgcuv2egSA4Uf+r2nTJ8JVk4kazSLdclwqZPD1LvPML+VIJlW1AxmRRmz9aPpPrjL5LHj6/VbXfffeVYrQqpqfo7z8mxc8895Yb2qeXaa6uDj02jRxWnglP2venxR5YVrrvOda7D+ZfNJpDsgW3CRZJzu4daqz9xz2+QoXfQjPXtBQKBQBAbjj7azr33lrNhQxxvvpnY0sNpVuwDBlBx552UPvtsSw8FOMJE8sCBDfzyy8GoJqKp/VlpYO3aQiTJu8xfJPtrkxdfLPG0HTXS1/6g3TbUpKy0FAf5+QWMHh06K4P/WBrLvn0HmDRJX+z6o1oXVI45Rv/YJk2qZffuAx7bhT8bNxYybVpwwRuMwYNt3H+/vrjWRpIVh4JDMumOWcVkglNOaSA/v8Az2bBP7xDntiGwH71IsnpT8tBDZYw5O/xnlZnubfPow37FU8KJYCGSBQKBoE1y3XXVDB9ez/33p7FpU+uwHjQLkkTVLbfg7NSppUcCHCEiWY2oego0RKEdtJFkNfOB+rjcPxrp378sa8bjF3HUirRQkV+v3SL0OINFRoMRLpIcCaH2rXdsTfEIKdhn6x9JdkihI8n6SSFCfD46keRwWBKCZ55Qj0PS3FxIfubwsMuOnboAACAASURBVB+dEMkCgUDQJpFlWLiwDJsNLrigo14cRtAMHBEiWcUjPBohkq00YDYrYewWBLxXt/cXU/F4I8Mh7RGKMZEcaST5zjsrwzcKwwUX1PL88yVBo7LQdCL51lt9xx+sDLRa5hngz2fVeuwWwcasZ5kJ9bWRoqgnakkMLpI7d3ZyySXV/P1G7/FlpvvtQ9gtBAKBoN3SvbuDKVNcT5/ffffIsl20Fo4Ikax6OT25Z6OotKeNJFutio/dwt8rGiiSFe94/KKBCXitDKHsFpLiWhduslskxSZMshI2d68Rnn++lAsuqKNXbnBbht6xBRO0kXDHHf4iWb+dNj90UoLTgCdZZ2EozRmhSJYkiAshkmUZnniinO5dvf3Kit85FHYLgUAgaNfcf385p5xSz6xZ6Wzf3m5zLbRajgiRrAohVWBmZ0cuDLUi2WJxiZhgdgt/gaUV1P52i0RNijYjkeRwtSEisVukpDZeIGtJT2rqSHJ4UW1EJKMonvrwRkRyuL1KKDG3W3j61t5U+c8EDHcCj8Qp0QKBQNCOsFrhwQddc22mTs2IqUVSEJ52dRV9881irr/elZFAK5IvneAqJqJqhmCTu4IhSYqP3UIVqsHsFv4RUq1I9hdTkUaSw+kebQq4cNaLG66PfHJcKG78W2nQdXrHFqmGM5KtI7hI1rxxOlFM4ewW2v36/u+PoqA7cS8s5hAiWf0lDCWSw0SKxW+pQCAQtH369LFz5ZXV7NplZtasI7PISEvRrkTymWfWM3y4S6yoAhagd3eXEFU1xbHHRhb1S0hQ8M+THEl2C1kGp3qq/USyWWOPMBJJDvcE3Yzd00+4qHKHDm0rkizjDFrtL1yfgZHkKOwWQVCQDEeSfaIAoQzmeiLZP4Qg7BYCgUBwRPDAA+VkZzt4660ktmw5grJdtDDtSiRDkAlXbr9otE+ftYJYjTwec4zNp0CIFqfTV5zIslckhhJTRrJbhEM7llAT6ULRsWOUReNDRFNjIZIlFPr2DS1Gg+lCn3RzioI5znUT1bOLvo9azy9tDZKyDkXRPfauXUOPVQnlnVEFsUYYS5HaLYRIFggEgnaBLMOyZa40oHfdlUZtrfh9bw7anUhWdYHP432bS6yEmrA3WhOh1LMGjBnr6kONPN5/fznX3+jyE/uLZD0t8/QCd45b/xrP2nYG7Bbh0NotIk0HB/Dpp4f54ovDEW8HoW8AYjFxT0Jh1qzQhU2C6UKfoK2ikJLh+uo//UQhM2YEZvjQ6yejg5O33y7mxht12usc+0cfFYUca0iDufo90UaP/b5YIgWcQCAQHDn072/nkUfK2LLFwujRHanXKxcriCntUiTP4UFuylnuWZa5YxNfMYrnNp9G1jnnkJObG7CdthKffwRWkiA1wyU4HuBecDiIj4ej+7vWX8kbnM/7nvZdC/L4ilGeZV02f0G/Nx5y9b15M+Zff9Ufu1v2XMZb/JsJXM8LWN1Cd17+NEPHH0kk2bRvH+l//zvav7Shzjw6KQf5nLO4jSc8y+WDB/mUsVzK23SYNo04Teo6065dZE6aRPqdd3rbl5fTuV8/z/tUKsjJzSX1/vtJu+MOsv/0J+IP5weMSTGZoKGB9BtvJOsvfyFxyRJvnzixWMCEnTe4gtT77iNz8mR6scu9scKY/9zOCL7x6XM6i8geMcLzXlIUj0DtNOVibtsaeG77bPqPZlBuOSpJjC3/J7euOIeB/OhdjeST3WI/uXzHn8j9eTWm664j6/zzSZk/H4BB+Z/xEecSV18eWsQqCkkvv0zKwoXeZf43WMJuIRAIBEcUl19ew4MPlrN3r5nJk7PERL4mpt3lE+nZ085fuQcKvMs6/bqOvuzkB/k0rD99p7+hRk/oplHTPvYuL0fJyPB53P0+f/GI3KP/WMso1rGbXnzABZz2yKU+XSX85z8oshxQHELd/i2uAGACXqHWt/5n7SEFJWQZYz9SnnsOgNrJkz3LMqdMofS55ziLVZzFKgpwjd3yyy+M5XPG8jm8D+fwCSsYD4D1+++J27AhcCxV3hLa17AYgOQXX/Qs6/Xcfez128Y2ZAhxX39N4sqVrr7z8jzrzhnritwPYxNX8Ba85Fp+Anns5ihoaGDw16/yOq/69NmTvfCHZoGi+Hx2PVctDRj7mFf+RsF9+d727v8Tly0jo2A9p/A/T1sJxccKkUsBuRRQtXo1ptdfx4TrJqNy1iyu2TqLDLaTlPR76EouikLCypXI5eXY+vTBsmNHwPdF2C0EAoHgyOOyy2q47740Nm2yctNN6Tz9dJn4uW8i2l0kuU+fQGGoiot5g5fTMGyY7naSz2sdX7NGoHjaBhE55jC5jKUg24WyW0SDUR9zAHrjCyPowqFrt9C83kp/bH374sjODtrHUwv0s2dEfJwhLC+66BzfrLvKfVfrtNEKZ/UzT7W4PNDHHmPzjOMGng86xoYhQyhTo8kRZrcQv5oCgUDQ/jCbYfXqQgDeey+Rrl1zWL/e2sKjap+0O5Gsh+RwWxBkY6LBX9BJEr4iSBVZQcSWWY5u4ltYsacoYQWpto+oRbfecYUSlgZEp+6Nh+bjcCKHFXVWs/5+PMdp9LmTokQmIHX6TU32fsZOJP1zoPUp+/fhdHqWOXX+DCW1jSR5xyrsFgKBQCAAevZ0sG9fAVdf7Xpie9FFWTz+eEoLj6r9cUSI5DiTS6xcdHFtcCGl0ROGRXKQviwmA+JUR8C0ZpEcLPp93nkhzmmQcenuEtllHzAQsT55pG8aOPU4g41Rrx+lsQLS58mCoi+StZFf//UakaxNV6gdo0ckq7YKYbcQCAQCgRuTCR54oII77nBNaF+wIIXnn0+K+GGpIDhHhEhWvblnjA6e7UErJ3TFpfZbF0Ykm2W3aAslDHUEjIyTE08MMV3V6YzIKtAckeQXXywN9MoaHIv2FKgZOUIen/t8z57tm13C07fRcxMDu0VAH3p2C20k2d9/rigeUa8rkp1O13mVZY+gD0gBJyLJAoFAcMRz661VvPtuEV26OHjggTSGDOlEVZX4/Y8FR4RI9kT0QkXeJO3LwIp5PujksNUSzpMcfAiKbz5ffwxEkrVEK5J1I7Kh9hul3QI9u0UU+4lYJMfAbqFdpiiS/o2CwUiynt1C/awV7Xc2UruFQCAQCI4ITjmlgc8+c6VvLSoyMW5cFnv2hEgzKjDEESGSJa1I9hMWf/97JbNnVwSNJI8aVccLL5RGZLc4urcrGhzphDIJJWQRNq2wCsZZo2vJzDQQyQ6FkchpuPZ+6HqStV0guTJ+RDFB8KzRtcycWRHRDUREhBHJV11ZFf6c+a/X3PAEtVuoWThUoewfSRYIBAKBwE1mppP8/AIeeqiM/HwTJ5/ciTFjOnLo0BEh9ZqEI+PMqY+9dTyvc+ZUMn16lc8yrUhetqyEUaPqfT2oaonoIKIs3ur09NO7dxCLRxC7Raj6EkbsFiNGNDDypHpPf1HRBBP3wtktPAuiEOPjzq3hppuqDEeSjdhDwu1X20ffvnZ9H7fGbhHwXdF8lsHsFv4T9yIet0AgEAiOOK68soY33igBYOtWC9ddl8HBg0eG3Is1R8ZZU8VKqMfTISbugZ/ICZPdQl0eqUiVUEhJCVV1z4DdQtMmpiK5kSng9KPaGssCUli7RbCbEinc5xGw2wjtFnpo9xVM3DfWbhEuu4VAIBAIBDqMHNnArl0FXHZZNXl5Vs44I5utW1tPaYyCApkDB1q/BG39I4wBHhFlUBjpissI7BaGRGqQ7Bb331+u09i737BHoBHJ4YqJhNpPwNj8lt1+WwXPPVeiu06PcCngevWyh8/WEOx8OyPPbhGJSNbt199KESKSrJhMuhP3DGW3EHYLgUAgEERBXBw88kg5S5YUEx+vcNZZHXn4YblVVOn70586c8IJnVt6GGE5IkQyDocrQ0AIYRSumIiuv7QxIlmHgQPq6dAhTMQ2nCDVtIlaJBuYuHfssXb+8hd3KrYo7Rbak56UpERttwgb2Q/W3igGPNq6QloVtWZzxCng1OwXitZHLyLJAoFAIIgASYKzzqpn2bJiFEVi3jwzffp0prZWTPw2whEhkiWHwxuNCyaUdewWKclBJl6FEWVqZDWaiXshMTBxLxaR5LCRU719huszzMQ9z+cSTRaNcDctwdobJVz7YDYR93gVkynkxL2QdguNSBaeZIFAIBBEQ//+dvbtK2DECCd1dTJ9+3amoaGlR9X6OSJEMuAVycF8rdqmbpF86aU1+m2DiDK1TKQhT7KuWI+BSFbz6xKBSNabVKa371DjCsO5ZweeS59ToBbNiMb7rC5vBk+yZ9Km1voQxm6ByaQ7cS9knmRVREuSt/CJsFsIBAKBIEpMJvj8cztdujhwOiV69cph167mTxPXGuweRjlyRHIEokgVt8nJOtFj/9ca+vWz+6yP2JOshBZ5UoR2CzP20G1V9KwAev2G2mcYkhINCFgpSL7hMPuJauJeJGjbq6/tfuc21MQ9HU9yNNkthEgWCAQCQWOIi4ONGw8xcaIrcDVmTDY1Nc1rvairaztWD0NTHTdv3sxrr72G0+lk9OjRXHjhhT7rbTYbixYtYteuXaSkpHDLLbeQnZ2N3W7nhRdeYPfu3TidTkaNGsX48eOb5EDCEmZSmKRjt/BBRygFFXQaT7KiRDBBLBZlqTXR5mgiyUowX7D/fjUnzJANQC+Nmux7bpRwkeQw2USMTtwzPMHPMzADVhu9sWkm7gWco2jyJAu7hUAgEAgaiSTBwoVlDB5s49570zj66C6sXXuI3r2bJxDjH2NqzYSNJDudThYvXsycOXNYsGAB69evZ//+/T5tVq9eTVJSEs888wzjxo1j6dKlAHzzzTfY7XaeeOIJ5s+fz6pVqygsLGyaIwmDEkEkedw5OtaACMpSG5m4p7dluEiyobLUmjaGRbJ/DugweYEBfeFocB+aTvx2YnDiXjB7SHNM3NOzW+iNSdtGZ+KeZDSSrPUki0iyQCAQCGKAJMHUqdXceWcFAKNGdeLLL+OaZd9akfzyy0mtOv4TViTv2LGDzp0706lTJ8xmMyNHjmTjxo0+bfLy8jj99NMBGDFiBD///DOKWzTU1dXhcDhoaGjAbDaTmJgY+6MwQgQT9+LjGpcCLuqJe0b8xuE6iUUKuKaYuKcnIn3ehM4+4tNebxKcwXFE1E6vvfraT7CGmuwY7cQ9yekU2S0EAoFA0GTcfHMVt9/uEsqXX55Jfn7Tu3AdDu+1ft68tFaVv9mfsCMrKSkhMzPT8z4zM5Pt27cHbWMymUhMTKSyspIRI0aQl5fHddddR0NDA1deeSXJyckB+1i1ahWrVq0CYP78+WRlZUV+IGZzyO0kk4msrCzMfnWf1W2UeO8dVJzFAkBiYiJx7vVm9zKADmlpKFlZyAkJun2ZrFZAraAXGCVMSEhA0hGEZrMp5DFkpKeDu+9gJMbHI7n3aVQkp2o+E0mWSdHcyKjjkf1ublJSU0lW1/mdBz2sOuOO05xzs9nsMks5naSmpur20SEtDbKykPzWJyUkkJCVBeUhckxrSE5KQo4Lf8fsOfaUFAAsZrNH2CZojiclJQXq6wO2V79pJosFSVHIysz0fB9SkpORqqsB/UhyRocOyJJEfEICFvffVrzfOQz3dxLN31GkhPu7a8u052MTCAQCcMVgbrutiowMJ3ffnc7YsR1ZteownTs3XVDG5leI+PffLQwY0Do9GE0q33fs2IEsy7z44otUV1czd+5cjj/+eDp16uTTbsyYMYwZM8bzvqioKOJ9ZWVlebbL0VmvSBJFRUVk2WxopYa6TVJ9PapsaqitJQGoqamh0r0+o76eePf6spISbEVFJFVVkabTV1pNDUm4RLJD5xF5bU0NiRAQFXbaGigqKtIdP0BJURFYrYRKv11TXY3VfSx9etbDnhCN3VSWl5Phfq04nVRVVJDud0yJmmUAlRUV1LnXJVdWoi9rvajn1GeZRlja7XYUmw3sdqoqKsgkkNKSEhzJyVhLS9FKl5qqKqqKijAVF9NJZzt/qioqSGhoIJxMVo893n1+bDYbUn09VqCuqookd7vKykqkujqf8wPgqK9HBhyShBkoOnyYbIcDM1BZVoZcWUk6+iK5tLiYLLuduoYGqsrK6ATUV1ejvVUJ9neSE2Z9LNH+3bU3oj22nJxgf8ECgUDQOrnqqhp697ZzySVZjBzZidWrC+nZs2ksfmokefLkGtaujWPFigQmTKhtkn01lrBx9YyMDIqLiz3vi4uLycjICNrG4XBQU1NDSkoK//vf/xg8eDBms5m0tDT69evHzp07Y3wIfgR7lB7Wk6zzSD1Yv40tJhI0BVmYSXmh9qmi9S0b9bAambgXMBjN+I3YF/TaaPtQ7RahJicGS/XWnGWpg53bMBP3AtpoUsAFzZOspoALtQ+BQCAQCGLAqac2cMUV1dTXS9xwQwfq6ppmP6on+ZRT6hk9uo6vvorj559bp+UirEju3bs3Bw4coLCwELvdztdff80JJ5zg02bYsGGsWbMGcE3WGzBgAJIkkZWVxc8//wy4vMnbt28nNzc39kehJYiQCDdxz2dtOJFscOJeQpyDefN0LADBipAYEcARZLcwLJI17YKlmQs1cS/a7BY+y9x5koNNHATCZpaIOGuFQSS9G6RQExnV7dRfAtXio/lstMc56nRbwLaiLLVAIBAImpv588t55plStmyxcvTRXSgri326Nu2lcfr0KqxWhYULU2K+n1gQViSbTCamTp3Kgw8+yK233spJJ51Et27dePfdd8nLywPgzDPPpKqqihkzZvDhhx9y2WWXAXD22WdTV1fHbbfdxuzZsznjjDPo0aNH0x5RMMEWJgVc2D50slsEFWXu9X8aWsfo0YFe1aAi2UgxkQiyWxiu0GZA8DW2mEjwIi46UexwlfUaGUmOuHKdul9NlN1IdgvPePRSuGmO885ZOkVr3EVhxMQ9gUAgEDQnEybUMn16JU6nxPTpHaiNsRNCtVuYTAo9ejgYP76Wjz9O4OOP48Ns2fwYim8PHTqUoUOH+iy7+OKLPa+tViu33XZbwHbx8fG6y5uUYMK1kSJZiiCSbEiE6RYTiUHFPW0k1mDk0V/wGSpLrRddDTcuvX3jF002YreIRXaLaO0WeufWnYkiAHcbRY0ka/erOU7dpxzaPMmiLLVAIBAImpHZsyvJzHRy331p/PWvmSxdWhwub4Bh/B+yTp9exdKlSTz1VArnnltHQwNYLNFfpmNJ+6u4F2UkWZuEQleMaO0FwSKa/mMItz5wJyHHGGlZ6mjsFp796O1bS6R5koOMu1O2Zt/hSodrrQp6fTeVJzlcMZFgFhW/X4KAGy31vU4GFE+farluEHYLgUAgEDQb111XzTXXVPH113FMm9YhZuWktZFkgO7dHdx2WyW//GLh+eeTGDiwM3fdlRaqi2aj3YnkoNHYaEWRir8oCtZOuzyYrUIVP/7LwxUTUZTw0WaNYDNcfELTzvDEvQgjybo3HpJEx0y7z3sfkR9sn3qFOXSWB6URxUQ8ObC12dCDiGTPeQ1mtwghkj2eZW3+aBFJFggEAkEzcu+9FYwZU8ennyZw8cWZMYnVqCngtBl5r7rKlRL1gQfSqKyUefvtJD7/vHmKm4Si3YnkoEKisSI5iol7QcVelBP3Qk5qU9tEMXFPimbinrZKX2Mm7qnbam0IUXqSDU/cU5SIKjCGKyYi19QQ/+mngdup2S10Ju752Er0nnJoJ+4JkSwQCASCFsBigSVLSkhNdbJ+fRznn5/VaKGsRpK1Ijkz08krr5T4tLvrrnR27dJ50tqMtM6cG40hWHaLxk7c01sfY7uFoYl7TZECLpJJaHptGmG38NlWlkOL5DDZLSKyW0SCVtjq7Cvt3nt1N/PcPOhEkiVNCjjd76ZGJKuCXpSlFvizefNmXnvtNZxOJ6NHj+bCCy/0WW+z2Vi0aBG7du0iJSWFW265hezsbOx2Oy+88AK7d+/G6XQyatQoxo8fD8CHH37I6tWrkSSJbt26ceONN+oWAxIIBEcGkgRfflnI1KkZ/PijlSlTMnn77WJdp2A43nsvgZoaVST7XovPOaeOadOqeP75ZJYvL+KaazI49dRO5OUdpEuXlgkStb9Isp8A8uSojUF2C918tzpEP3HPeOaKoGgilNFmtzAycc+n70ZM3PNPAyeFuhGI5cS9SAgTSQ6K2ibYxD31HOr90rhFtMhuIQiG0+lk8eLFzJkzhwULFrB+/Xr279/v02b16tUkJSXxzDPPMG7cOJYuXQq4UnXa7XaeeOIJ5s+fz6pVqygsLKSkpIRPPvnk/9u7/5im7/wP4M9PP6WFUii0FRjMzYFuTp0axch5U0G5nbfoZUec7lcuZpcYqcMws2Rs2RlzFzezO5ScQCAXo4tZLttdpom7ZD+IA8M4N1DxB24KyCaZaIUCthQo9PP+/lFa2w/99YFi6ef7evyjtJ9P+371Td+8+u7r/f7g4MGDKC8vhyAIaGpqikZ4hJBZJCNDwKlTvZg/fwyNjWps3WrA3bvSUsjxcaCkJBVvv+269JbSzzTte+/dx40bPfj1rx145x3X5bJzczNw+3Z00lX5JcniRGIKSbLfJJGxB481zZpkz4KsyScGb1gY5RZTWbjHhVOTHCgxnXjOkPy1250UT/yfuXe3CFFuMd2Fe1wEFu6FNasrKrcIuHAv0Ewy1SSTIDo6OpCRkYH09HQolUqsWbMGzc3NPse0tLQgPz8fAJCXl4erV6+CTfzejYyMwOl0wuFwQKlUQjNx6XlBEOBwODz3paamPtS4CCGzk0oFfPFFL1JTnfj+ezVWrMiAwxH++ffu+f6tcy/cE0tMdN3+6qt2bNzouqLJqlUZuHw5bmoNnwbZJ8me2V8pSVGAJNH9WJ5dFqZYbhHovIiUW3gnmTO5u0WkZpK9a5Inyi1C7T897YV709gCTspzcWEu3AtabuG1uwWVWxBvFosFBsODC7gbDAZYLJaAx/A8D41GA6vViry8PMTHx2Pnzp0wmUzYsmULtFot9Ho9tmzZguLiYuzcuRMajQbLli17qHERQmavhASGy5fvYskSV3b8xBOZ+Pbb8Mqx7t71/dY01J9RpRL4xz/6PT//7ndzYLE83H3hZFeTPCnBCpUk+0uYAi1cE5dbTGfh3hTKLTjGwMKplw404xpIsIV77tdH/FjihC+EgNvqicotgs4kB3o+qQv3wvmwIW6n+Lm8d7cIxN9lqf3VNwcot5i0cI+SZBIhHR0dUCgUqK2txdDQEPbt24dnnnkGiYmJaG5uRlVVFTQaDQ4dOoSzZ89i3bp1kx6jrq4OdXV1AICDBw/CaDRKaoNSqZR8TiyRc3wUW+yKVHwtLcA//zmOkhIlXnrJgB9+GMO8eaHOcv0tM5mcqK7m8cwzOoRqitEIjI46sH27EqdOKVBSko7//GccSX4u0DcTfSe7JHlSAjUxCxdw4Z6/JDlQuYV4RlDijGfANk4I52IioT5DceHULfs7x5u4Bte7LMLPMWHVPod4LZi7rCBIkhxwf+qpzCRLSJLDuix1sPO8d7dw3xeq3MJ9jHeSLLWWmsiaXq9HX1+f5+e+vj7o9Xq/xxgMBjidTtjtdiQlJaGxsRHLly+HUqmETqfDU089hc7OTnAch7S0NCQnJwMAVq9ejRs3bvhNkgsLC1FYWOj5ube3V1L7jUaj5HNiiZzjo9hiVyTjKyoCkpLUeP11PZ56SoWjRy3YtGkk4PFmsxqAAZs3W/Duu2PgOCDcphw5AixcqMXBg8kwGlWoqzPj6ad9J6umGltmZmbA++RXbiF14V44OzlMHDdp4Z7EJDjoc7ruCH5euOUWUpOpYLtbhCpxEB8fSIg6Y9eDhrjiXqAPJ1NYuBf2rLM37xl1KR9EvGvZ/SW8/vZJdn94UCjoYiLEr5ycHPT09MBsNmN8fBxNTU3Izc31OWblypWor68H4Fqst3jxYnAcB6PRiKtXrwJw1Sa3t7cjKysLRqMR7e3tGB0dBWMMV65cQVZW1sMOjRASI37zm1EcP+4q8/rTn/SorU0M+Kd4ZMT19y8+nkmueFQoAJPJhj/8wQ4AKCxMw3//Gz/jc0fyn0kOlSR7l1G4TXPhXsgr8gU8L4zkOpxSBKkLvEQL9/wmwNNduOevPEG8SND9c6jXbZoL9yS/Rv5iDafcwn26n5lk7wWWfr/lcPeJ18I9qkkm3niex+uvv44DBw5AEAQUFBRg7ty5+OSTT5CTk4Pc3Fxs2LABlZWVKCkpgVarRWlpKQBg06ZNqK6uxt69e8EYQ0FBAR5//HEArgV+b7/9Nniex7x583xmiwkhRGzjxlF88kkvtm834i9/0YExYNeuoUnHeSfJU8HzQGXlAJ5+ehzvv5+MnTv1WL7cgc8/752xS1j//0mSg9Uke/8Lr2RE/DW7aOFeyDYEm2n2c58+xYnJv1ai88KYSQ5767cJQS8mEigWiTPJfhM877Z6l1tIrfWWWm7h9ViSj5Wyu4Wbe+Gdd2zefenvd9MrSfY8O+1uQURWrFiBFStW+Ny2fft2z/9VKhX27t076bz4+Hi/twPAtm3bsG3btsg2lBAia88+68CNGz3YutWAv/5Vh2+/VaOmpt+zUwXwIElWq6c3/bt7tw3r14/gt79NQ2urCkVFBnz8sSX0iVMgu3KLSQmse5YuUJLsL/HwlyS760O9zwk14xlsdws/SVq8OvTCvbBmkqV+/yCeFfWXJE9z4V7AUgGvx2UKhesiGxJ3DZG6u0XQvZiDtdE7qZeSJPvbX3uiL5nX7hU+bfTeGYPKLQghhMxyiYkMn33Wi6IiO86ciceTTz6CW7cefFM/3Zlkb0uWjKOp6S4A4Pvv1diwYQ66uqb9sJPILkkOuAXcVGqSRTPJ4prkUFuVBU32ApV0BBNGcjeVhXvBSikCbncnXoQWipSaf4NtPAAADDhJREFUZKkfPqTubiG1bnuKC/c8pwRbuOe9D7I397F0MRFCCCExIiEBOHJkAK+84vpe/Fe/SsdHH2kgCMDoaOSSZAB4/HEnbt26jV27bOjuVmLTpjgMD0e27kJ+5Rbi5GciQQm0uwWHieVyIcotOMZ8r5zm77nEbQh2v5/7QiZ54SR3U1i4N+liIv6SwmCPOdVyC++aZO8ZVamv6xQW7k03SZZUbhFo4R5jvjPF3vzMJFNNMiGEkFjwt78NguOAjz9OxLvvpuDLL+OxdOkYOI5BrY7c8/A88Oc/38fataO4ciUFHBfZlXyySJL5mzfB/e9/UFut4M1m3zvdCUiAJFn99ddg8fFQ/vyz5zZucBAAoOzshPqrr1y33b8PxLmu9qJqbQVTqcCL5vbdx/L37rnOGRry3ObT3jt3oLDbJ92usFj8Hu+m+u47sISEgPcDAN/TA24oaGXz5HM6Ox/8v78fyps3PT+r6+rAEhImxRp37dqDeEWXwvXH/Zr6PG93N3jRdi2czYa4tja/j6H+7jso+vsRd+WK7+PcugX1V19BdflyyHYAgLKjAwpL6Pold3xx1665nqenB9yIa3sbf/EE4p5JVp896+kb5Y8/uh4rwEyyauLKad6XpZbynIQQQkg0ffjhIIqLbXj22XQ0NMSjoSEeycnCjCyyy88fxdatzrC3lAsXx5jEaceH4Pbt25KO11ZVIfn99yfdLiQmYmzRIqibmzGybh0s//oXtEeOIPngwSm1ayQ/H+qGhqltH0aCGnzvPfA9PdAePRrtpkTc4P790O3f7/c+p9GIuy0tyAywC/vA3/8O+0svIWPRIiju3/e57/Yvv/g9J23tWihv3gx4fyTJeU/RmdhzU86kjtty/t0B5B0fxRa7ohXf5s1GXLyowgcfDOCPf5w8SRgJMzFmy2Im2f7ii0j4/e8xMDAAYGL2jTEIRiNYQgKUt25hfCIJse3eDfurrwKCAIXZ7PMVtpCYCABQDA2B8fykr7fH5s8H39sLxcTzAICg04GzWifV5TqzssB7JSlMoQBLSgJTKsFPXADAmZ7u2r1AowEcDignZmQZx4ElJYGzWgGOQ8rChejv6oJieNh1f0IC4HRCSEkBZ7e7Zid5HoJO9+CxJ57fXUfNEhNd30s4HK4ZTJUK3PCwJ073frzuK8k509Oh6OvzubKckJICxcCA39fGmZkJhdmM8XnzoLx1y/Wc8fFgSiU4pxOKwUGw+HhgdHRS+YDusccwlJwMOBwYfvFF17k8DxYfD254GJwgeBb1eV5Pnnf1cXo6+J4en9s5p9Pzr6DTgbPZIMyZA85mA9NoPN82CCkpEJKSXHEKAuBwPNjFxOn0+TDkeVyOg5CZ6XptOQ6YaCNTKCDMmQNFXx/AGJwZGVD+8gt0c+diSKfD6Pr14EZHPb8ziolZYWdGBhAXhzstLa4ZY6cTioEBV8w8j/GFCwGOg7m+HrzZDEGngzMtLWjphfnrr8O7IiAhhBDyEPz7373o71fgkUdia22NLGaSAXl/+pNzbIC845NzbIC846OZZGloJtmXnOOj2GKXnOOjK+4RQgghhBDyEFCSTAghhBBCiAglyYQQQgghhIhQkkwIIYQQQogIJcmEEEIIIYSIUJJMCCGEEEKICCXJhBBCCCGEiFCSTAghhBBCiAglyYQQQgghhIhQkkwIIYQQQojIrLwsNSGEEEIIIdEkm5nksrKyaDdhxsg5NkDe8ck5NkDe8ck5ttlA7q+vnOOj2GKXnOObidhkkyQTQgghhBASKZQkE0IIIYQQIsLv379/f7QbESnZ2dnRbsKMkXNsgLzjk3NsgLzjk3Nss4HcX185x0exxS45xxfp2GjhHiGEEEIIISJUbkEIIYQQQoiIMtoNiITW1lYcO3YMgiBg48aNeOGFF6LdJEl6e3tRVVWFgYEBcByHwsJCPP/887DZbDh8+DDu3buHOXPm4M0334RWqwVjDMeOHcPFixehVqthMplm/dcngiCgrKwMer0eZWVlMJvNqKiogNVqRXZ2NkpKSqBUKjE2NobKykrcvHkTSUlJKC0tRVpaWrSbH9TQ0BBqamrQ3d0NjuNQXFyMzMxMWfTd559/jjNnzoDjOMydOxcmkwkDAwMx23fV1dW4cOECdDodysvLAWBK77P6+np89tlnAICioiLk5+dHK6SYRGP27H7fAzRmx2rf0Zgd4TGbxTin08neeOMNdufOHTY2Nsbeeust1t3dHe1mSWKxWFhnZydjjDG73c727NnDuru72YkTJ9jJkycZY4ydPHmSnThxgjHG2Pnz59mBAweYIAjs+vXr7J133ola28N1+vRpVlFRwT744APGGGPl5eWssbGRMcZYbW0t+/LLLxljjH3xxRestraWMcZYY2MjO3ToUHQaLMGRI0dYXV0dY4yxsbExZrPZZNF3fX19zGQysdHRUcaYq8+++eabmO67trY21tnZyfbu3eu5TWpfWa1Wtnv3bma1Wn3+T8JDY/bsft+70Zgde31HY3bkx+yYL7fo6OhARkYG0tPToVQqsWbNGjQ3N0e7WZKkpqZ6Pu0kJCQgKysLFosFzc3NWL9+PQBg/fr1nrhaWlqwbt06cByHJ598EkNDQ+jv749a+0Pp6+vDhQsXsHHjRgAAYwxtbW3Iy8sDAOTn5/vE5v6El5eXh6tXr4LN4rJ5u92OH374ARs2bAAAKJVKJCYmyqbvBEGAw+GA0+mEw+FASkpKTPfdokWLoNVqfW6T2letra1YunQptFottFotli5ditbW1oceS6yiMXv2v+9pzI7dvqMxO7JjdsyXW1gsFhgMBs/PBoMB7e3tUWzR9JjNZnR1dWH+/PkYHBxEamoqACAlJQWDg4MAXDEbjUbPOQaDARaLxXPsbHP8+HG89tprGB4eBgBYrVZoNBrwPA8A0Ov1sFgsAHz7k+d5aDQaWK1WJCcnR6fxIZjNZiQnJ6O6uho///wzsrOzsWPHDln0nV6vx5YtW1BcXAyVSoVly5YhOztbNn3nJrWvxGOO92tAQqMxe3a/7wEas2O172jMjvyYHfMzyXIyMjKC8vJy7NixAxqNxuc+juPAcVyUWjZ158+fh06nm9U1XNPhdDrR1dWF5557Dh9++CHUajVOnTrlc0ys9p3NZkNzczOqqqpQW1uLkZER2c+YxmpfkeigMTv20JgtLzPdVzE/k6zX69HX1+f5ua+vD3q9Pootmprx8XGUl5dj7dq1WL16NQBAp9Ohv78fqamp6O/v93y60+v16O3t9Zw7m2O+fv06WlpacPHiRTgcDgwPD+P48eOw2+1wOp3geR4Wi8XTfnd/GgwGOJ1O2O12JCUlRTmKwAwGAwwGAxYsWADA9ZXVqVOnZNF3V65cQVpamqftq1evxvXr12XTd25S+0qv1+PatWue2y0WCxYtWvTQ2x2raMye3THTmB27fUdjduTH7JifSc7JyUFPTw/MZjPGx8fR1NSE3NzcaDdLEsYYampqkJWVhc2bN3tuz83NRUNDAwCgoaEBq1at8tx+9uxZMMZw48YNaDSaWfnVDwC88sorqKmpQVVVFUpLS7FkyRLs2bMHixcvxrlz5wC4Vp26+2zlypWor68HAJw7dw6LFy+e1Z/oU1JSYDAYcPv2bQCuQerRRx+VRd8ZjUa0t7djdHQUjDFPbHLpOzepfbV8+XJcunQJNpsNNpsNly5dwvLly6MZQkyhMXt2v+9pzI7dvqMxO/JjtiwuJnLhwgV89NFHEAQBBQUFKCoqinaTJPnxxx+xb98+PPbYY55f0JdffhkLFizA4cOH0dvbO2mbk6NHj+LSpUtQqVQwmUzIycmJchShtbW14fTp0ygrK8Pdu3dRUVEBm82GJ554AiUlJYiLi4PD4UBlZSW6urqg1WpRWlqK9PT0aDc9qJ9++gk1NTUYHx9HWloaTCYTGGOy6LtPP/0UTU1N4Hke8+bNw65du2CxWGK27yoqKnDt2jVYrVbodDps27YNq1atktxXZ86cwcmTJwG4thMqKCiIZlgxh8bs2f2+d6MxO/b6jsbsyI7ZskiSCSGEEEIIiaSYL7cghBBCCCEk0ihJJoQQQgghRISSZEIIIYQQQkQoSSaEEEIIIUSEkmRCCCGEEEJEKEkmhBBCCCFEhJJkQgghhBBCRChJJoQQQgghROT/ADpE79t4uadpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(x, acc, 'b', label='Training acc')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    \n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
